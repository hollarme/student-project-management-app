{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "497a1d44-8332-4d2f-aa88-5077ccc7ab0d",
   "metadata": {},
   "source": [
    "https://obikastanya.medium.com/easy-way-to-integrate-your-python-apps-with-google-drive-api-2f29ed0be239\n",
    "https://towardsdatascience.com/automate-streamlit-web-app-using-interactive-aggrid-with-google-sheets-81b93fd9e648"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6322564-f75f-493f-907c-997423391d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting student-project-management-app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile student-project-management-app.py \n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "import gspread \n",
    "from gspread.exceptions import WorksheetNotFound, SpreadsheetNotFound\n",
    "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "from googleapiclient.http import MediaFileUpload, MediaIoBaseUpload\n",
    "\n",
    "\n",
    "folder_id = None\n",
    "parent_folder_id = None\n",
    "\n",
    "class GoogleDriveService:\n",
    "    def __init__(self):\n",
    "        self._SCOPES=['https://www.googleapis.com/auth/drive', 'https://spreadsheets.google.com/feeds', \n",
    "                      'https://www.googleapis.com/auth/drive.file']\n",
    "        \n",
    "        # self.ServiceAccountCredentials = st.secrets['ServiceAccountCredentials']\n",
    "        # st.write(st.secrets['ServiceAccountCredentials'])\n",
    "        # self.jsonString = json.dumps({key:value for key, value in self.ServiceAccountCredentials.items()})\n",
    "        \n",
    "    def build(self):\n",
    "        creds = service_account.Credentials.from_service_account_info(st.secrets[\"ServiceAccountCredentialsSheet\"], scopes = self._SCOPES)\n",
    "        service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "        return service\n",
    "    \n",
    "def getFileListFromGDrive():\n",
    "    selected_fields=\"files(id,name,webViewLink)\"\n",
    "    g_drive_service=GoogleDriveService().build()\n",
    "    list_file=g_drive_service.files().list(fields=selected_fields).execute()\n",
    "    return {\"files\":list_file.get(\"files\")}\n",
    "\n",
    "\n",
    "def create_folder(folder_name, parent_folder_id):\n",
    "    \"\"\" Create a folder in the parent folder \n",
    "    Returns : new folder Id\n",
    "    \"\"\"\n",
    "\n",
    "    files_to_download = getFileListFromGDrive()\n",
    "\n",
    "    if folder_name in [file['name'] for file in files_to_download['files']]:\n",
    "        raise FileExistsError\n",
    "    \n",
    "    try:\n",
    "        # create drive api client\n",
    "        service = GoogleDriveService().build()\n",
    "        file_metadata = {\n",
    "            'name': f'{folder_name}',\n",
    "            'parents' : [f'{parent_folder_id}'],\n",
    "            'mimeType': 'application/vnd.google-apps.folder'\n",
    "        }\n",
    "\n",
    "        file = service.files().create(body=file_metadata, fields='id').execute()\n",
    "        return file.get('id')\n",
    "    except HttpError as error:\n",
    "        print(F'An error occurred: {error}')\n",
    "        return None\n",
    "    \n",
    "#     new_permission = {\n",
    "#           'emailAddress': 'eakinboboye@oauife.edu.ng',\n",
    "#           'type': 'user',\n",
    "#           'role': 'writer'\n",
    "#         }\n",
    "        \n",
    "#     try:\n",
    "#         service.permissions().create(fileId=file.get('id'), body=new_permission, supportsAllDrives=True).execute()\n",
    "#         return file.get('id')\n",
    "#     except HttpError as error:\n",
    "#         print ('An error occurred: %s' % error)\n",
    "#         return None\n",
    "    \n",
    "def upload_to_folder(folder_id, file_name, file):\n",
    "    \"\"\"Upload a file to the specified folder and prints file ID, folder ID\n",
    "    Args: Id of the folder\n",
    "    Returns: ID of the file uploaded\n",
    "    \"\"\"\n",
    "    files_uploaded = getFileListFromGDrive()\n",
    "\n",
    "    if file_name in [file['name'] for file in files_uploaded['files'] if file['name'].endswith('.pdf')]:\n",
    "        raise FileExistsError\n",
    "        \n",
    "    try:\n",
    "        # create drive api client\n",
    "        service = GoogleDriveService().build()\n",
    "\n",
    "        file_metadata = {\n",
    "            'name': f'{file_name}',\n",
    "            'parents': [folder_id]\n",
    "        }\n",
    "        media = MediaIoBaseUpload(file,\n",
    "                                mimetype='application/pdf', resumable=True)\n",
    "        # pylint: disable=maybe-no-member\n",
    "        file = service.files().create(body=file_metadata, media_body=media,\n",
    "                                      fields='id').execute()\n",
    "        print(F'File ID: \"{file.get(\"id\")}\".')\n",
    "        return file.get('id')\n",
    "\n",
    "    except HttpError as error:\n",
    "        print(F'An error occurred: {error}')\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_database(parent_folder_id, db_name, sheet):\n",
    "        # Create a list of scope values to pass to the credentials object\n",
    "        scope = ['https://spreadsheets.google.com/feeds',\n",
    "                'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "        # Create a credentials object using the service account info and scope values\n",
    "        credentials = service_account.Credentials.from_service_account_info(\n",
    "                    st.secrets[\"ServiceAccountCredentialsSheet\"], scopes = scope)\n",
    "\n",
    "        # Authorize the connection to Google Sheets using the credentials object\n",
    "        gc = gspread.authorize(credentials)\n",
    "        \n",
    "        try:\n",
    "            # Open the Google Sheets document with the specified name\n",
    "            sh = gc.open(db_name)\n",
    "        except SpreadsheetNotFound:\n",
    "            # Create the Google Sheets document with the specified name\n",
    "            sh = gc.create(db_name)\n",
    "        try:\n",
    "            # Access the worksheet within the document with the specified name\n",
    "            worksheet = sh.worksheet(sheet) \n",
    "        except WorksheetNotFound:\n",
    "            #Create the worksheet for the user\n",
    "            worksheet = sh.add_worksheet(sheet, rows=1000, cols=50)\n",
    "            \n",
    "        return worksheet\n",
    "\n",
    "\n",
    "setup, tab0, tab1, tab2 = st.tabs([\"Setup\", \"Information\", \"Grouping\", \"File Upload\"])\n",
    "\n",
    "with setup:\n",
    "    \n",
    "    st.header('Setup Page')\n",
    "    \n",
    "    session = st.selectbox(\n",
    "    'What is the current session?',\n",
    "    ('2021/2022', '2022/2023', '2023/2024', '2024/2025', '2025/2026', '2026/2027', '2027/2028', '2028/2029', '2029/2030'))\n",
    "    #create folders (with the above session names) manually in eakinboboye@oauife.edu.ng and share with sheet-admin@examtools.iam.gserviceaccount.com\n",
    "    \n",
    "    semester = st.selectbox(\n",
    "    'What is the current semester?',\n",
    "    ('Rain', 'Harmattan'))\n",
    "    \n",
    "    parent_folder_name = f\"{session}-{semester}\"\n",
    "            \n",
    "    result = getFileListFromGDrive()\n",
    "        \n",
    "    parent_folder_id = [dic['id'] for dic in result.get('files') if dic['name']==parent_folder_name][0]\n",
    "            \n",
    "            \n",
    "\n",
    "with tab0:\n",
    "  \n",
    "    st.markdown('''\n",
    "                _`EEE 501 & 502` project management application_\n",
    "                \n",
    "                ''')\n",
    "\n",
    "        \n",
    "    with st.expander('UPLOADING FILES', expanded=False):\n",
    "        st.markdown('''\n",
    "                    You are required to submit the final (corrected) copy of you thesis: use the file upload tab!\n",
    "                    \n",
    "                    __Note__: only pdf files are accepted!\n",
    "                    \n",
    "                    \n",
    "                    ''')\n",
    "\n",
    "with tab1:\n",
    "    try:\n",
    "        grouping_tables = get_as_dataframe(get_database(parent_folder_id, \"Defense Grouping List\", 'Sheet1'),usecols=['Reg. Number','Names','Adviser','Group','Staff']).dropna(how='all')#pd.read_csv('defense_grouping_list.csv', nrows=1000)\n",
    "        grouping_tables.set_index('Reg. Number',inplace=True)\n",
    "        grouping_table = [grouping_tables.loc[indices,:] for indices in grouping_tables.groupby('Group').groups.values()]\n",
    "    except FileNotFoundError:\n",
    "        grouping_tables = pd.DataFrame({})\n",
    "\n",
    "    st.write('## Defense Grouping List')\n",
    "    st.dataframe(grouping_tables)\n",
    "\n",
    "with tab2:\n",
    "    file = None\n",
    "    \n",
    "    st.write('### Upload a PDF file against your registration number')    \n",
    "\n",
    "    folder_name = st.selectbox(\n",
    "    f'Select your registration number:',\n",
    "    [student for student in grouping_tables.index], key=1)\n",
    "\n",
    "    # st.write(f'You are in Group {grouping_tables.loc[folder_name].Group if folder_name else 0: 1}')\n",
    "    try:\n",
    "        folder_id = create_folder(parent_folder_id, folder_name)\n",
    "    except FileExistsError:\n",
    "        all_files = getFileListFromGDrive()\n",
    "        folder_id = [file['id'] for file in all_files['files'] if file['name']==folder_name][0]\n",
    "    \n",
    "    topic_dataframe = get_as_dataframe(get_database(parent_folder_id, 'Topic List', 'Sheet1'),usecols=['Number','Topic']).dropna(how='all')\n",
    "    try:\n",
    "        topic = topic_dataframe[topic_dataframe.Number==folder_name]['Topic'].values[0]\n",
    "    except IndexError:\n",
    "        topic = \"\"\n",
    "    project_title = st.text_area('Enter the title of your project here...', value=topic)\n",
    "    topic_dataframe.loc[topic_dataframe.Number==folder_name, 'Topic'] = project_title\n",
    "    st.button('Save', on_click=set_with_dataframe(get_database(parent_folder_id, 'Topic List', 'Sheet1'), topic_dataframe))\n",
    "    \n",
    "    st.write('Upload your file(s) below:')\n",
    "    file_type = st.radio(\n",
    "    \"What type of file is it?\",\n",
    "    (None,'Thesis', 'Slide'), horizontal=True)\n",
    "\n",
    "    file=st.file_uploader(\"Choose a PDF file\", type=['pdf'], accept_multiple_files=False)\n",
    "     \n",
    "    if file:\n",
    "        if file_type:\n",
    "            file_name = f\"{folder_name}-{file.name.split('.')[0]}-{file_type}.pdf\"\n",
    "            try:\n",
    "                upload_to_folder(folder_id, file_name, file)\n",
    "            except FileExistsError:\n",
    "                st.warning(f\"The file exists already. Either close the file or rename your file like so :red['{file.name.split('.')[0]}-v1.0.pdf']\", icon=\"⚠️\")\n",
    "        else:\n",
    "            st.warning('Make sure you select a file type', icon=\"⚠️\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b1577bd-c135-4d90-8f9b-92c52ffb9ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import gspread \n",
    "from google.oauth2 import service_account\n",
    "\n",
    "\n",
    "# Create a list of scope values to pass to the credentials object\n",
    "scope = ['https://spreadsheets.google.com/feeds',\n",
    "        'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "# Create a credentials object using the service account info and scope values\n",
    "credentials = service_account.Credentials.from_service_account_info(\n",
    "            st.secrets[\"ServiceAccountCredentialsSheet\"], scopes = scope)\n",
    "\n",
    "# Authorize the connection to Google Sheets using the credentials object\n",
    "gc = gspread.authorize(credentials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a3a15d57-f464-4540-a588-1aea418cebb0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-13 15:11:20.517 INFO    googleapiclient.discovery_cache: file_cache is only supported with oauth2client<4.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder ID: \"1n0-wVknumYSaIyiTip9YvuKtwfQ3mzIm\".\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import google.auth\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "\n",
    "def create_folder():\n",
    "    \"\"\" Create a folder and prints the folder ID\n",
    "    Returns : Folder Id\n",
    "\n",
    "    Load pre-authorized user credentials from the environment.\n",
    "    TODO(developer) - See https://developers.google.com/identity\n",
    "    for guides on implementing OAuth2 for the application.\n",
    "    \"\"\"\n",
    "    # creds, _ = google.auth.default()\n",
    "\n",
    "    try:\n",
    "        # create drive api client\n",
    "        service = build('drive', 'v3', credentials=credentials)\n",
    "        file_metadata = {\n",
    "            'name': '2021/2022-Rain',\n",
    "            'mimeType': 'application/vnd.google-apps.folder'\n",
    "        }\n",
    "\n",
    "        # pylint: disable=maybe-no-member\n",
    "        file = service.files().create(body=file_metadata, fields='id'\n",
    "                                      ).execute()\n",
    "        print(F'Folder ID: \"{file.get(\"id\")}\".')\n",
    "        return file.get('id')\n",
    "\n",
    "    except HttpError as error:\n",
    "        print(F'An error occurred: {error}')\n",
    "        return None\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    create_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ab5269f-2bed-4172-9797-a5baba312524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Spreadsheet 'absolute.csv' id:12xHVrCxzCFvyARFwwLLTx7WxYb4YHoFH4TRzHpwZTDM>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.create('absolute.csv', '1EJQyD0NghC1lxalJCWINQYvqAZdnGDve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "64afc784-c76c-49d6-a017-f782a1320091",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '1J1QXvrGvqbF2m5nYCKAjwccEdomFC04N68MwjMr0uDM',\n",
       "  'name': 'Group Score Sheet',\n",
       "  'createdTime': '2023-08-13T14:35:20.124Z',\n",
       "  'modifiedTime': '2023-08-13T14:35:20.207Z'},\n",
       " {'id': '1kgYSqNB-pHRamxeLQbW0ZIIUUKjYSWB8FUoXcuPJ2dc',\n",
       "  'name': 'Supervisor Score Sheet',\n",
       "  'createdTime': '2023-08-13T14:35:16.626Z',\n",
       "  'modifiedTime': '2023-08-13T14:35:16.704Z'},\n",
       " {'id': '1_7Vm1qBD8BNE9s0Om9p2pgiODaOXb1HIbPmYCvAo7uw',\n",
       "  'name': 'Defense Grouping List',\n",
       "  'createdTime': '2023-08-13T14:35:12.140Z',\n",
       "  'modifiedTime': '2023-08-13T14:35:12.208Z'}]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.list_spreadsheet_files(folder_id=\"1EJQyD0NghC1lxalJCWINQYvqAZdnGDve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a3b51294-5a1b-4d77-87b3-60fc00b4c976",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "service.files().delete(fileId=\"1qKb0z2w6G9em7GEV5P2R6mdusiaYjq7A9c3iVjr0zzE\").execute();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "531d7c91-b82a-40e3-998e-3eafb436d177",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-13 14:32:53.459 INFO    googleapiclient.discovery_cache: file_cache is only supported with oauth2client<4.0.0\n"
     ]
    }
   ],
   "source": [
    "# Connect to the API service\n",
    "service = build('drive', 'v3', credentials=credentials)\n",
    "\n",
    "# request a list of first N files or \n",
    "# folders with name and id from the API.\n",
    "resource = service.files()\n",
    "result = resource.list(pageSize=20, fields=\"files(id, name)\").execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7aa2a14e-0999-42f9-8766-09e2dbe7399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileListFromGDrive(cred):\n",
    "    selected_fields=\"files(id,name,webViewLink)\"\n",
    "    g_drive_service=build('drive', 'v3', credentials=cred)\n",
    "    list_file=g_drive_service.files().list(fields=selected_fields).execute()\n",
    "    return {\"files\":list_file.get(\"files\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8606b6b9-ec77-42a6-bfe9-9cf148539d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-13 15:14:06.739 INFO    googleapiclient.discovery_cache: file_cache is only supported with oauth2client<4.0.0\n"
     ]
    }
   ],
   "source": [
    "result = getFileListFromGDrive(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0c7afdc2-811e-4c41-bbf3-59aa40f8a853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1EJQyD0NghC1lxalJCWINQYvqAZdnGDve'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dic['id'] for dic in result.get('files') if dic['name'] == '2021/2022-Rain'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "86732b7c-27e3-4401-89f2-f450d79a664d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting project-management-app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile project-management-app.py \n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.errors import MergeError\n",
    "import math\n",
    "# import streamlit_authenticator as stauth\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from google.oauth2 import service_account\n",
    "# from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "import json\n",
    "import gspread \n",
    "from gspread.exceptions import WorksheetNotFound, SpreadsheetNotFound, APIError\n",
    "\n",
    "from st_aggrid import AgGrid, JsCode\n",
    "from st_aggrid.grid_options_builder import GridOptionsBuilder\n",
    "\n",
    "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
    "\n",
    "from annotated_text import annotated_text\n",
    "\n",
    "import pyTigerGraph as tg\n",
    "\n",
    "st.set_page_config(page_title=\"Capstone Project Manager\", layout=\"wide\") \n",
    "\n",
    "# Initialize connection.\n",
    "conn = tg.TigerGraphConnection(**st.secrets[\"tigergraph\"])\n",
    "conn.apiToken = conn.getToken(st.secrets[\"tg_secret\"])\n",
    "\n",
    "# authToken = authToken[0]\n",
    "\n",
    "\n",
    "\n",
    "checkbox_renderer = JsCode(\"\"\"\n",
    "class CheckboxRenderer{\n",
    "\n",
    "    init(params) {\n",
    "        this.params = params;\n",
    "\n",
    "        this.eGui = document.createElement('input');\n",
    "        this.eGui.type = 'checkbox';\n",
    "        this.eGui.checked = params.value;\n",
    "\n",
    "        this.checkedHandler = this.checkedHandler.bind(this);\n",
    "        this.eGui.addEventListener('click', this.checkedHandler);\n",
    "    }\n",
    "\n",
    "    checkedHandler(e) {\n",
    "        let checked = e.target.checked;\n",
    "        let colId = this.params.column.colId;\n",
    "        this.params.node.setDataValue(colId, checked);\n",
    "    }\n",
    "\n",
    "    getGui(params) {\n",
    "        return this.eGui;\n",
    "    }\n",
    "\n",
    "    destroy(params) {\n",
    "    this.eGui.removeEventListener('click', this.checkedHandler);\n",
    "    }\n",
    "}//end class\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "authenticated_user = st.experimental_user.email\n",
    "st.write(authenticated_user)\n",
    "\n",
    "save_master_copy = True\n",
    "disable_available_adviser = False\n",
    "not_admin = False   \n",
    "\n",
    "folder_id = None\n",
    "\n",
    "# Create a list of scope values to pass to the credentials object\n",
    "scope = ['https://spreadsheets.google.com/feeds',\n",
    "        'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "drive_credentials = service_account.Credentials.from_service_account_info(st.secrets[\"ServiceAccountCredentials\"], scopes=scope)\n",
    "\n",
    "\n",
    "# Create a credentials object using the service account info and scope values\n",
    "sheet_credentials = service_account.Credentials.from_service_account_info(st.secrets[\"ServiceAccountCredentialsSheet\"], scopes = scope)\n",
    "\n",
    "# @st.cache_resource\n",
    "# class GoogleDriveService:\n",
    "#     def __init__(self):\n",
    "#         self._SCOPES=['https://www.googleapis.com/auth/drive', 'https://spreadsheets.google.com/feeds']\n",
    "#         # self.ServiceAccountCredentials = st.secrets['ServiceAccountCredentials']\n",
    "#         # st.write(st.secrets['ServiceAccountCredentials'])\n",
    "#         # self.jsonString = json.dumps({key:value for key, value in self.ServiceAccountCredentials.items()})\n",
    "        \n",
    "#     def build(self):\n",
    "#         # with open(data_file:=\"data.json\", \"w\") as jf:\n",
    "#         #     jf.write(self.jsonString)\n",
    "#         # creds = ServiceAccountCredentials.from_json_keyfile_name(data_file, self._SCOPES)\n",
    "#         service = build('drive', 'v3', credentials=drive_credentials)\n",
    "\n",
    "#         return service\n",
    "    \n",
    "# @st.cache_resource\n",
    "def getFileListFromGDrive(cred):\n",
    "    selected_fields=\"files(id,name,webViewLink)\"\n",
    "    g_drive_service=build('drive', 'v3', credentials=cred)\n",
    "    list_file=g_drive_service.files().list(fields=selected_fields).execute()\n",
    "    return {\"files\":list_file.get(\"files\")}\n",
    "\n",
    "# @st.cache_resource\n",
    "def get_database(folder_id, db_name, sheet):\n",
    "        \n",
    "        # Authorize the connection to Google Sheets using the credentials object\n",
    "        gc = gspread.authorize(sheet_credentials)\n",
    "        \n",
    "        try:\n",
    "            # Open the Google Sheets document with the specified name\n",
    "            sh = gc.open(db_name, folder_id)\n",
    "        except SpreadsheetNotFound:\n",
    "            # Create the Google Sheets document with the specified name\n",
    "            sh = gc.create(db_name, folder_id)\n",
    "            # sh.share('eakinboboye@oauife.edu.ng', perm_type='user', role='editor')\n",
    "        try:\n",
    "            # Access the worksheet within the document with the specified name\n",
    "            worksheet = sh.worksheet(sheet) \n",
    "        except WorksheetNotFound:\n",
    "            #Create the worksheet for the user\n",
    "            worksheet = sh.add_worksheet(sheet, rows=1000, cols=50)\n",
    "            \n",
    "        return worksheet\n",
    "    \n",
    "def send_email(recipient, score_sheet):\n",
    "    from email.mime.text import MIMEText\n",
    "    from email.mime.application import MIMEApplication\n",
    "    from email.mime.multipart import MIMEMultipart\n",
    "    from smtplib import SMTP\n",
    "    import smtplib\n",
    "    import sys\n",
    "\n",
    "\n",
    "    recipients = [recipient] \n",
    "    emaillist = [elem.strip().split(',') for elem in recipients]\n",
    "    msg = MIMEMultipart()\n",
    "    msg['Subject'] = \"EEE 501 Project Result\"\n",
    "    msg['From'] = 'eakinboboye@oauife.edu.ng'\n",
    "\n",
    "    html = \"\"\"\\\n",
    "            <html>\n",
    "              <head></head>\n",
    "              <body>\n",
    "              <div>Please sir/ma, return grades for the students you supervised in \"EEE 501\".</div>\n",
    "              <div>The table below contains the score sheet for your students. </div>\n",
    "                {0}\n",
    "              <div>Thank you.</div>\n",
    "              </body>\n",
    "            </html>\n",
    "    \"\"\".format(score_sheet.to_html(index=False))\n",
    "\n",
    "    part1 = MIMEText(html, 'html')\n",
    "    msg.attach(part1)\n",
    "\n",
    "    try:\n",
    "        \"\"\"Checking for connection errors\"\"\"\n",
    "\n",
    "        server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "        server.ehlo()#NOT NECESSARY\n",
    "        server.starttls()\n",
    "        server.ehlo()#NOT NECESSARY\n",
    "        server.login('eakinboboye@oauife.edu.ng','learner@oauife007')\n",
    "        server.sendmail(msg['From'], emaillist , msg.as_string())\n",
    "        server.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error for connection: {}\".format(e))\n",
    "        \n",
    "name_email_map = {\n",
    "'Mr. Olorunniwo': 'dareniwo@oauife.edu.ng',\n",
    "'Mr. Aransiola': 'aaransiola@oauife.edu.ng',\n",
    "'Dr. Obayiuwana': 'obayiuwanae@oauife.edu.ng',\n",
    "'Dr. Yesufu': 'tyesufu@oauife.edu.ng',\n",
    "'Dr. Ariyo': 'ariyofunso@oauife.edu.ng',\n",
    "'Dr. Ogunseye': 'aaogunseye@oauife.edu.ng',\n",
    "'Mr. Olayiwola': 'solayiwola@oauife.edu.ng',\n",
    "'Dr. Mrs. Offiong': 'fboffiong@oauife.edu.ng',\n",
    "'Dr. Ayodele': 'kayodele@oauife.edu.ng',\n",
    "'Dr. Akinwale': 'olawale.akinwale@oauife.edu.ng',\n",
    "'Dr. Ilori': 'sojilori@oauife.edu.ng',\n",
    "'Mr. Akinboboye': 'eakinboboye@oauife.edu.ng',\n",
    "'Dr. Olawole': 'alex_olawole@oauife.edu.ng',\n",
    "'Dr. Babalola': 'babfisayo@oauife.edu.ng'\n",
    "}\n",
    "\n",
    "# dareniwo@oauife.edu.ng\n",
    "# aaransiola@oauife.edu.ng\n",
    "# obayiuwanae@oauife.edu.ng\n",
    "# tyesufu@oauife.edu.ng\n",
    "# ariyofunso@oauife.edu.ng\n",
    "# aaogunseye@oauife.edu.ng\n",
    "# solayiwola@oauife.edu.ng\n",
    "# fboffiong@oauife.edu.ng\n",
    "# kayodele@oauife.edu.ng\n",
    "# olawale.akinwale@oauife.edu.ng\n",
    "# sojilori@oauife.edu.ng\n",
    "# eakinboboye@oauife.edu.ng\n",
    "\n",
    "# supervisor_worksheet = get_database(\"Supervisor Score Sheet\", authenticated_user)\n",
    "\n",
    "# preload_worksheet = get_database(\"defense_grouping_list\", 'Sheet1')\n",
    "\n",
    "setup,tab0, tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([\"Setup\", \"Information\",\"Distribution\", \"Grouping\", \"Score Sheets\", \"Download Files\", \"I-defense Score Sheet\", \"I-supervisor Score Sheet\", 'Result'])\n",
    "\n",
    "with setup:\n",
    "    \n",
    "    st.header('Setup Page')\n",
    "    \n",
    "    session = st.selectbox(\n",
    "    'What is the current session?',\n",
    "    ('2021/2022', '2022/2023', '2023/2024', '2024/2025', '2025/2026', '2026/2027', '2027/2028', '2028/2029', '2029/2030'))\n",
    "    #create folders (with the above session names) manually in eakinboboye@oauife.edu.ng and share with sheet-admin@examtools.iam.gserviceaccount.com\n",
    "    \n",
    "    semester = st.selectbox(\n",
    "    'What is the current semester?',\n",
    "    ('Rain', 'Harmattan'))\n",
    "    \n",
    "    folder_name = f\"{session}-{semester}\"\n",
    "    \n",
    "    def create_files():\n",
    "        gc = gspread.authorize(sheet_credentials)\n",
    "        \n",
    "        result = getFileListFromGDrive(sheet_credentials)\n",
    "        try:\n",
    "            global folder_id\n",
    "            folder_id = [dic['id'] for dic in result.get('files') if dic['name']==folder_name][0]\n",
    "            \n",
    "            files_in_folder = [dic['name'] for dic in gc.list_spreadsheet_files(folder_id=folder_id)]\n",
    "                        \n",
    "            st.write(f'Files already in the folder: {\",\".join(files_in_folder)}.')\n",
    "            \n",
    "            for db_name in ['Defense Grouping List', 'Supervisor Score Sheet', 'Group Score Sheet']:\n",
    "                if db_name in files_in_folder:\n",
    "                    pass\n",
    "                else:\n",
    "                    gc.create(db_name, folder_id)\n",
    "        except IndexError:\n",
    "            print(f\"Folder {folder_name} has not been created yet!\")\n",
    "            \n",
    "    st.button('Create working files', on_click=create_files)\n",
    "        \n",
    "    \n",
    "with tab0:\n",
    "    # user_name = [name for name in adviser if authenticated_user.find(name.split(\" \")[1].lower())==1][0]\n",
    "\n",
    "    st.header(f'Project Management App')\n",
    "   \n",
    "    st.markdown('''\n",
    "                _This tool was developed to help manage `EEE 501 & 502` essentially. The tool is to be employed by staff members only!_\n",
    "                \n",
    "                ''')\n",
    "    \n",
    "    with st.expander('GUIDELINE FOR EEE 501/502 Report and Presentation Format', expanded=False):\n",
    "        st.markdown('''\n",
    "                    The reports and presentations must be organised thus:\n",
    "                    \n",
    "                    1. `Introduction`: Clearly state the background to the problem\n",
    "\n",
    "                    2. `Problem Statement`: What problem are you trying to solve and the significance of your solution\n",
    "\n",
    "                    3. `Aim and specific objectives of the project`: What is the overall goal of your solution? What are the technical objectives required to achieve the solution?\n",
    "\n",
    "                    4. `Literature Review`: What are the existing solutions to the problem and what are the limitations of these solutions? At least three (4) reviewed solutions should be explicitly presented in your project report. Existing reviewed solutions should be analyzed and summarized in tabular form on a single slide for your defense seminar listing the pros and cons. \n",
    "                    \n",
    "                    5. `Methodology`: What is your solution? What are the step-by-step procedures used in the implementation of your solution? What are the fundamental engineering principles/theories used in your solution? Block Diagram(s)/Circuit Diagram(s)/Flow Charts of your solution or subsystem of your solution must be presented etc\n",
    "                    \n",
    "                    6. `Current Status of Project and Preliminary Results`: What is the current status of the project? Do you have preliminary results? Like simulations etc. What are the implications of your solution? \n",
    "                    \n",
    "                    7. `Future Plans`: What are your future plans? Discuss in terms of:\n",
    "                        - deliverables\n",
    "                        - timeline\n",
    "                        - budget, etc.\n",
    "                    \n",
    "                    ''')\n",
    "    with st.expander('REQUIREMENTS', expanded=False):\n",
    "        st.markdown('''\n",
    "                    __Presentation slides__: students should prepare no more than fifteen (15) slides for the defense seminar\n",
    "                     \n",
    "                    __Endorsement of project report__: supervisors must endorse all reports and preview slides before projects can be assessed by the panel during defense seminar.\n",
    "                   \n",
    "                    __Report grading__: the student is required to revise the project report based on comments/suggestions/modifications by the assessors during the defense seminar. Revised project report and solution should be submitted to the supervisor for grading within one (1) week after your defense seminar.\n",
    "                    ''')\n",
    "        \n",
    "    with st.expander('HOW TO SAVE FILES INTO THE PROVIDED GOOGLE DRIVE', expanded=False):\n",
    "        st.markdown('''\n",
    "                    You are going to save `thesis and slides) into the provided [Google drive](https://drive.google.com/drive/folders/1XJ63r2NSU3Bsv4pCiI8z1F7FFO0ugsXA?usp=sharing) using the naming convention below:2 files` (\n",
    "                    \n",
    "                    __Your thesis filed be named__xxxx/xxx-thesis.pdf: EEG/ shoul\n",
    "                    \n",
    "                    __Your presentation file hould be named__/xxx-slides.pdf: EEG/xxxxs\n",
    "                    \n",
    "                    > e.g. EEG/2006/059-thesis.pdf and EEG/2006/059-slides.pdf\n",
    "                    \n",
    "                    \n",
    "                    __Note__: only pdf files are accepted!\n",
    "                    \n",
    "                    \n",
    "                    Just put the 2 files into the `EEE 501/502 Project Management APP` folder. __Don't__ create a new folder please!\n",
    "                    ''')\n",
    "\n",
    "    \n",
    "# @st.cache_data(ttl=300)\n",
    "def load_data():\n",
    "    # DATA_URL = \"2021 EEE 501-502.csv\"\n",
    "    # return pd.read_csv(DATA_URL, nrows=1000)\n",
    "    return get_as_dataframe(get_database(folder_id, \"Defense Grouping List\", 'Sheet1'), usecols=['Names','Reg. Number','Adviser','Option'])\n",
    "    \n",
    "def drop_na(data):\n",
    "    return data.dropna(how='all')\n",
    "\n",
    "def sort_data(data):\n",
    "    return data.sort_values(by=['Option'])\n",
    "\n",
    "def set_ind(sorted_data):\n",
    "    # return sorted_data.set_index(['Adviser'])\n",
    "    return sorted_data.reset_index(drop=True)\n",
    "\n",
    "data = load_data()\n",
    "ddata = drop_na(data)\n",
    "sorted_data = sort_data(ddata)\n",
    "indexed_data = set_ind(sorted_data)\n",
    "\n",
    "with tab1:\n",
    "    # ssmap_data = indexed_data.loc[:,['Names', 'Reg. Number', 'Adviser']]\n",
    "    \n",
    "    st.header(f'Staff-Student Distribution for {folder_name}')\n",
    "    # AgGrid(indexed_data.loc[:,['Names', 'Reg. Number', 'Adviser', 'Option']].sort_values(by=['Adviser']))\n",
    "    st.experimental_data_editor(indexed_data.loc[:,['Names', 'Reg. Number', 'Adviser']].sort_values(by=['Adviser']))\n",
    "    \n",
    "with tab2:\n",
    "    \n",
    "    preload = st.checkbox('Load the allocation done by the admin', value=not_admin)\n",
    "    \n",
    "    # grouping_table = []\n",
    "    grouping_tables = pd.DataFrame({})\n",
    "    \n",
    "    adviser = indexed_data['Adviser'].drop_duplicates().values\n",
    "    \n",
    "    available_adviser = st.multiselect(\n",
    "    'Select the available staff members:', adviser, default=[], disabled=disable_available_adviser)\n",
    "    \n",
    "    #get the unavailable members and change the availability status in the tigergraph\n",
    "    @st.cache_data(ttl=120)\n",
    "    def update_staff_availability(adviser, available_adviser):\n",
    "        if available_adviser:\n",
    "            unavailable_adviser = list(set(adviser)-set(available_adviser))\n",
    "            for adviser in unavailable_adviser:\n",
    "                conn.upsertVertex(\"Staff\", adviser, {'available': False})\n",
    "                \n",
    "    update_staff_availability(adviser, available_adviser)\n",
    "    \n",
    "    number_of_groups = st.number_input('Insert the number of groups you want', min_value=1, disabled=not_admin)\n",
    "    \n",
    "    offset = 1\n",
    "    groups = dict(zip(list(range(1,number_of_groups+1)),[available_adviser[i::number_of_groups] for i in range(number_of_groups)]))\n",
    "    \n",
    "    # st.write(groups)\n",
    "    \n",
    "    students_total_no = len(indexed_data['Names'].to_list())\n",
    "    try:\n",
    "        students_ratio = dict(zip(list(range(1,number_of_groups+1)),[round((len(value)/len(available_adviser)) * students_total_no) for value in groups.values()]))\n",
    "    except ZeroDivisionError:\n",
    "        students_ratio = dict(zip(list(range(1,number_of_groups+1)),[0 for value in groups.values()]))\n",
    "\n",
    "    if not sum(students_ratio.values())==students_total_no:\n",
    "        diff = students_total_no - sum(students_ratio.values())\n",
    "        students_ratio[1] += diff\n",
    "        \n",
    "    indexed_data_copy = indexed_data.copy()\n",
    "    \n",
    "    indexed_data_copy.set_index('Reg. Number',inplace=True)\n",
    "\n",
    "    random_state = st.slider('Vary randomness for best fit', 0, 100, 1)\n",
    "    \n",
    "    student_div = dict(zip(list(range(1,number_of_groups+1)),[[] for i in range(number_of_groups)]))\n",
    "    for student_reg in indexed_data_copy.sample(frac = 1, replace=False, random_state=random_state).index:\n",
    "        for key in range(1,number_of_groups+1):\n",
    "            if pd.isna(student_reg):\n",
    "                break\n",
    "            try:\n",
    "                if student_reg not in indexed_data_copy[eval(\"^\".join([f\"(indexed_data_copy.Adviser=='{i}')\" for i in groups[key]]))].index and len(student_div[key])!=students_ratio[key]:\n",
    "                    student_div[key].append(student_reg)\n",
    "                    break\n",
    "            except SyntaxError:\n",
    "                pass\n",
    "            \n",
    "    if not preload:\n",
    "        # adviser_group = dict([item for sublist in [list(zip(v,[k]*len(v))) for k,v in groups.items()] for item in sublist])\n",
    "        \n",
    "        grouping_tables = pd.concat(grouping_table:=[indexed_data_copy.loc[value].assign(Group=key).assign(Staff=\", \".join(groups[key])) for key,value in student_div.items()])\n",
    "        \n",
    "        # grouping_tables.assign(StaffGroup=[adviser_group[adv] for adv in indexed_data_copy.Adviser if adv in available_adviser])\n",
    "        \n",
    "        if pd.concat([indexed_data.dropna().Names, grouping_tables.Names]).drop_duplicates(keep=False).shape[0] > 1:\n",
    "            st.write('## Unallocated Students:', pd.concat([indexed_data.dropna().Names, grouping_tables.Names]).drop_duplicates(keep=False))\n",
    "        elif pd.concat([indexed_data.dropna().Names, grouping_tables.Names]).drop_duplicates(keep=False).shape[0] == 1:\n",
    "            reg_number = indexed_data.iloc[pd.concat([indexed_data.dropna().Names, grouping_tables.Names]).drop_duplicates(keep=False).index[0]]['Reg. Number']\n",
    "            student_div[number_of_groups].append(student_div[1].pop())\n",
    "            student_div[1].append(reg_number)\n",
    "\n",
    "            grouping_tables = pd.concat(grouping_table:=[indexed_data_copy.loc[value].assign(Group=key).assign(Staff=\", \".join(groups[key])) for key,value in student_div.items()])\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            grouping_tables = get_as_dataframe(get_database(folder_id, \"Defense Grouping List\", 'Sheet1'),usecols=['Reg. Number','Names','Adviser','Group','Staff', 'Option']).dropna(how='all')#pd.read_csv('defense_grouping_list.csv', nrows=1000)\n",
    "            grouping_tables.set_index('Reg. Number',inplace=True)\n",
    "            grouping_table = [grouping_tables.loc[indices,:] for indices in grouping_tables.groupby('Group').groups.values()]\n",
    "        except FileNotFoundError:\n",
    "            grouping_tables = pd.DataFrame({})\n",
    "        \n",
    "    st.write('## Defense Grouping List')\n",
    "    st.dataframe(grouping_tables)\n",
    "    \n",
    "    if save_master_copy and not grouping_tables.empty:\n",
    "        st.button('save admin copy', on_click=set_with_dataframe(get_database(folder_id, \"Defense Grouping List\", 'Sheet1'), grouping_tables, include_index=True))\n",
    "    \n",
    "    #@st.experimental_memo\n",
    "    def convert_df(df):\n",
    "        # IMPORTANT: Cache the conversion to prevent computation on every rerun\n",
    "        return df.to_csv().encode('utf-8')\n",
    "\n",
    "    if not grouping_tables.empty:\n",
    "        csv = convert_df(grouping_tables)\n",
    "\n",
    "        st.download_button(\n",
    "            label=\"Download list as CSV\",\n",
    "            data=csv,\n",
    "            file_name='Defense Grouping List.csv',\n",
    "            mime='text/csv',\n",
    "        )\n",
    "    \n",
    "with tab3:\n",
    "    interactive_tables = []\n",
    "    \n",
    "    try:\n",
    "        for i,table in enumerate(grouping_table):\n",
    "            table['Presentation(10)'] = np.nan\n",
    "            table['Understanding(10)'] = np.nan\n",
    "            table['Creativity(10)'] = np.nan\n",
    "            table['Answer to Questions(5)'] = np.nan\n",
    "            table['Appearance(3)'] = np.nan\n",
    "            table['Attendance(2)'] = np.nan\n",
    "            table['Total(40)'] = np.nan\n",
    "            \n",
    "            staff_list = table['Staff'].drop_duplicates().values\n",
    "            \n",
    "            interactive_tables.append(table)\n",
    "                        \n",
    "            table = table.drop(columns=['Staff', 'Adviser', 'Group']).reset_index(drop=False)\n",
    "            # table.reset_index(drop=False, inplace=True)\n",
    "            \n",
    "            st.write(f'Group {i+1} Score Sheet: {staff_list[0]}')\n",
    "            st.dataframe(table)\n",
    "            \n",
    "            csv = convert_df(table)\n",
    "\n",
    "            st.download_button(\n",
    "                label=f\"Download Group {i+1} Score sheet as CSV\",\n",
    "                data=csv,\n",
    "                file_name=f'Group {i+1} Score sheet.csv',\n",
    "                mime='text/csv',\n",
    "            )\n",
    "    except (NameError, IndexError):\n",
    "        st.write(f'### You have not created the defense grouping list yet!')\n",
    "    # except IndexError:\n",
    "        \n",
    "\n",
    "with tab4:\n",
    "    files_to_download = getFileListFromGDrive(drive_credentials)\n",
    "    \n",
    "    col1, col2, col3 = st.columns([2,4,4])\n",
    "    \n",
    "    with col1:\n",
    "        filtar = st.selectbox(\n",
    "        'Filter with groups',\n",
    "        [f'Group {grp}' for grp in groups.keys()] if not preload else [f'Group {grp}' for grp in range(1,len(grouping_table)+1)]\n",
    "        )\n",
    "        \n",
    "        \n",
    "    with col2:\n",
    "        opt = st.selectbox(\n",
    "        f'Select a registration number:',\n",
    "        [student for student in grouping_tables.index if (grouping_tables.loc[student].Group == int(filtar.split(\" \")[1])).any()], key=2)\n",
    "        \n",
    "    with col3:\n",
    "        # placeholder = st.empty()\n",
    "        \n",
    "        try:\n",
    "            file = st.selectbox(\n",
    "            f'Select the file to download:',\n",
    "            [file['name'] for file in files_to_download['files'] if file['name'].startswith(opt.replace('/','_'))], key=3)#!='EEE 501/502 Project Management APP'], key=3)\n",
    "\n",
    "            data =  [f['webViewLink'] for f in files_to_download['files'] if f['name'].startswith(file)]\n",
    "            \n",
    "            st.markdown(f\"[Open {file.split('-')[1]} for {file.split('-')[0]}]({data[0]})\", unsafe_allow_html=True)\n",
    "\n",
    "            # if st.button(f\"Open {file.split('-')[1]} for {file.split('-')[0]}\"):\n",
    "                # st.write(data[0])\n",
    "                # webbrowser.open(data[0])\n",
    "#             data_file = urlopen(data)\n",
    "                \n",
    "#             st.write(data_file.fp.read())\n",
    "            \n",
    "            # Download=st.download_button(label=f\"Download {file.split('-')[1]} for {file.split('-')[0]}\", data=b'', file_name=f'{file}',mime='application/pdf')\n",
    "        except (AttributeError,TypeError):\n",
    "            pass\n",
    "        except IndexError:\n",
    "            annotated_text(\n",
    "                            \"This \",\n",
    "                            (\"student\", f\"{opt}\", \"#8ef\"),\n",
    "                            \" might \",\n",
    "                            (\"not\", \"#8bf\"),\n",
    "                            \"have\",\n",
    "                            (\"formatted\", \"#afa\"),\n",
    "                            \"the\",\n",
    "                            (\"files:\", f\"{file}\", \"#fea\"),\n",
    "                            \"properly \",\n",
    "                            \"hence \",\n",
    "                            \"the submission is\",\n",
    "                            (\"invalid!\", \"#8ef\"),\n",
    "\n",
    "                        )\n",
    "            # placeholder.text('The student might not have formatted the files properly, hence the submission is invalid!')\n",
    "#     with st.expander(f'Question Pool for {opt}'):\n",
    "#         with st.form('Add Questions for a Student') as f:\n",
    "#             question_table = pd.DataFrame({'Reg. Number':[opt],'Question':[''],'Remark':[False]})\n",
    "#             # question_pool = get_as_dataframe(get_database(\"Question-Pool\", st.session_state.authenticated_user),usecols=['Reg. Number','Question','Remark']).dropna(how='all')\n",
    "\n",
    "#             gob = GridOptionsBuilder.from_dataframe(question_table)\n",
    "#             gob.configure_column('Remark', editable=True, cellRenderer=checkbox_renderer)\n",
    "#             gob.configure_default_column(editable=True)\n",
    "#             gridoptions = gob.build()\n",
    "#             AgGrid(question_table,\n",
    "#                     gridOptions = gridoptions, \n",
    "#                     editable=True,\n",
    "#                     allow_unsafe_jscode = True, \n",
    "#                     theme = 'balham',\n",
    "#                     height = 200,\n",
    "#                     fit_columns_on_grid_load = True)\n",
    "#             st.form_submit_button(\"Save\")\n",
    "        \n",
    "with tab5:\n",
    "    grp_filter = st.selectbox(\n",
    "        'Filter with groups',\n",
    "        [f'Group {grp}' for grp in groups.keys()] if not preload else [f'Group {grp}' for grp in range(1,len(grouping_table)+1)], key=4\n",
    "        )\n",
    "    avg_tables = []\n",
    "    table_to_edit = interactive_tables[int(grp_filter.split(\" \")[1])-1]\n",
    "    # st.write(table_to_edit)\n",
    "    try:\n",
    "        staff = table_to_edit['Staff'].drop_duplicates().values[0].split(',')#replace('. ', './').split(' ')\n",
    "        staff.append(grp_filter)\n",
    "\n",
    "        table_to_edit = table_to_edit.drop(columns=['Staff', 'Adviser', 'Group']).reset_index(drop=False)\n",
    "        table_to_edit.drop(columns='Option', inplace=True)\n",
    "\n",
    "        # st.write(staff)\n",
    "        for name in staff:\n",
    "            if not name.startswith('Group'):\n",
    "                try:\n",
    "                    int_table = get_as_dataframe(get_database(folder_id, \"Group Score Sheet\", name), usecols=table_to_edit.columns).dropna(how='all')#nrows=st.session_state['data_shape'][0], usecols=[i for i in range(st.session_state['data_shape'][1])])\n",
    "                    table_to_edit = table_to_edit.merge(int_table, how='right')\n",
    "                    table_to_edit = table_to_edit.replace(0, np.nan)\n",
    "                    avg_tables.append(table_to_edit)\n",
    "                except (MergeError, ValueError, APIError):\n",
    "                    table_to_edit = interactive_tables[int(grp_filter.split(\" \")[1])-1]\n",
    "                    table_to_edit = table_to_edit.drop(columns=['Staff', 'Adviser', 'Group']).reset_index(drop=False)\n",
    "                    table_to_edit.drop(columns='Option', inplace=True)\n",
    "                    table_to_edit = table_to_edit.replace(0, np.nan)\n",
    "\n",
    "\n",
    "            if name.startswith('Group'):\n",
    "                try:\n",
    "                    table_to_edit = pd.concat([table_to_edit[['Reg. Number','Names']], pd.concat(avg_tables).groupby(level=0).mean(numeric_only=True)], axis=1) #table_to_edit.merge(pd.concat(avg_tables).groupby(level=0).mean(), how='outer')\n",
    "                    avg_tables = []\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            # Create a GridOptionsBuilder object from our DataFrame\n",
    "#             gd = GridOptionsBuilder.from_dataframe(table_to_edit)\n",
    "\n",
    "#             # Configure the default column to be editable\n",
    "#             # sets the editable option to True for all columns\n",
    "#             gd.configure_default_column(editable=True)\n",
    "\n",
    "#             gridoptions = gd.build()\n",
    "            with st.expander(f'Score Sheet for {name}'):\n",
    "                with st.form(f'Score Sheet for {name}') as f:\n",
    "                    response = st.data_editor(table_to_edit, use_container_width=True, key=name)\n",
    "                    # response = AgGrid(table_to_edit,\n",
    "                    #                 gridOptions = gridoptions, \n",
    "                    #                 editable=True,\n",
    "                    #                 theme = 'balham',\n",
    "                    #                 height = 200,\n",
    "                    #                 fit_columns_on_grid_load = True)\n",
    "                    st.write(\" *Note: Don't forget to hit enter ↩ on new entry.*\")\n",
    "                    submit_defense = st.form_submit_button(\"Save\")\n",
    "                    if submit_defense:\n",
    "                        dss_data = response.replace(np.nan, 0)#response['data'].replace(np.nan, 0)\n",
    "                        cols = list(dss_data.columns)\n",
    "                        cols.remove('Total(40)')\n",
    "                        dss_data['Total(40)'] = dss_data[list(cols)].sum(axis=1,  numeric_only= True).values\n",
    "                        set_with_dataframe(get_database(folder_id, \"Group Score Sheet\", name), dss_data)\n",
    "                        if name.startswith('Group'):\n",
    "                            dss_data = response.replace(np.nan, 0)#response['data'].replace(np.nan, 0)\n",
    "                            conn.upsertVertexDataFrame(dss_data, vertexType='Average_Group_Score', v_id='Reg. Number', attributes={'reg_number':'Reg. Number', 'presentation':'Presentation(10)','creativity':'Creativity(10)','understanding':'Understanding(10)','appearance':'Appearance(3)','answer_to_questions':'Answer to Questions(5)','attendance':'Attendance(2)','total':'Total(40)'})\n",
    "                            conn.upsertEdgeDataFrame(dss_data, sourceVertexType='Student', edgeType='has_group_score', targetVertexType='Average_Group_Score',from_id='Reg. Number', to_id='Reg. Number', attributes={})\n",
    "    except (KeyError, IndexError):\n",
    "        st.write('#### Make sure that the students are allocated into groups first or sign in to use the service!')\n",
    "\n",
    "with tab6:\n",
    "    adviser_name = st.selectbox(\n",
    "        \"Filter with supervisor's name\",\n",
    "        [name for name in adviser], key=5)\n",
    "    \n",
    "    # super_table = indexed_data_copy[indexed_data_copy.Adviser==[name for name in adviser if authenticated_user.find(name.split(\" \")[1].lower())==1][0]]\n",
    "    super_table = indexed_data[indexed_data.Adviser==adviser_name]\n",
    "    super_table.drop(columns='Option', inplace=True)\n",
    "    super_table = super_table.loc[:,['Names', 'Reg. Number']]#.assign(Title=\"\").assign(Interaction(10)=\"\"})/\n",
    "    #.assign(Creativity(10)=\"\").assign(State of Project(10)=\"\").assign(Dedication(10)=\"\")/\n",
    "    #.assign(Quality of Report(20)=\"\").assign.assign(Total(60)=\"\")\n",
    "    super_table['Title'] = \"<insert Title>\"\n",
    "    super_table['Interaction(10)'] = np.nan\n",
    "    super_table['Creativity(10)'] = np.nan\n",
    "    super_table['State of Project(10)'] = np.nan\n",
    "    super_table['Dedication(10)'] = np.nan\n",
    "    super_table['Quality of Report(20)'] = np.nan\n",
    "    super_table['Total(60)'] = np.nan#super_table[list(super_table.columns)].sum(axis=1,  numeric_only= True)\n",
    "    try:\n",
    "        super_table_remote = get_as_dataframe(get_database(folder_id, \"Supervisor Score Sheet\", adviser_name), usecols=['Names','Reg. Number', 'Title', 'Interaction(10)', 'Creativity(10)', 'State of Project(10)', 'Dedication(10)', 'Quality of Report(20)', 'Total(60)']).dropna(how='all')\n",
    "        super_table = super_table.merge(super_table_remote, how='right')\n",
    "    except (MergeError, ValueError):\n",
    "        st.write('Cannot get saved table. Maybe no table is saved yet!')\n",
    "    # Create a GridOptionsBuilder object from our DataFrame\n",
    "    # gd = GridOptionsBuilder.from_dataframe(super_table)\n",
    "\n",
    "    # Configure the default column to be editable\n",
    "    # sets the editable option to True for all columns\n",
    "    \n",
    "    editable = True if 1 in [st.experimental_user.email.find(name.lower()) for name in adviser_name.split(\" \") if not name.endswith('.')] else False\n",
    "    if not editable:\n",
    "        editable = st.experimental_user.email in [\"eakinboboye@oauife.edu.ng\",  'test@localhost.com']\n",
    "        \n",
    "    # gd.configure_side_bar()\n",
    "    # gd.configure_default_column(groupable=True, value=True, aggFunc=\"sum\", editable=editable)\n",
    "    # gd.configure_column('Total(60)', valueGetter=\"Number(data['Interaction(10)']) + Number(data['Creativity(10)']) + Number(data['Dedication(10)']) + Number(data['State of Project(10)']) + Number(data['Quality of Report(20)'])\", type=['numericColumn'])\n",
    "    # gridoptions = gd.build()\n",
    "        \n",
    "    with st.form(f'Supervisor Score Sheet for {adviser_name}') as f:\n",
    "        response = st.data_editor(super_table, use_container_width=True, key=adviser_name)\n",
    "        # response = AgGrid(super_table,\n",
    "        #                 gridOptions = gridoptions, \n",
    "        #                 editable=True,\n",
    "        #                 theme = 'balham',\n",
    "        #                 height = 200,\n",
    "        #                 fit_columns_on_grid_load = True, \n",
    "        #                 enable_enterprise_modules=True)\n",
    "        st.write(\" *Note: Don't forget to hit enter ↩ on new entry.*\")\n",
    "        submit = st.form_submit_button(\"Save\")#on_click=set_with_dataframe(get_database(\"Supervisor Score Sheet\", adviser_name), response['data']))\n",
    "        if submit:\n",
    "            sss_data = response.replace(np.nan, 0)\n",
    "            cols = list(sss_data.columns)\n",
    "            cols.remove('Total(60)')\n",
    "            sss_data['Total(60)'] = sss_data[cols].sum(axis=1,  numeric_only= True).values\n",
    "            set_with_dataframe(get_database(folder_id, \"Supervisor Score Sheet\", adviser_name), sss_data)\n",
    "            conn.upsertVertexDataFrame(sss_data, vertexType='Supervisor_Score', v_id='Reg. Number', attributes={'reg_number':'Reg. Number', 'interaction':'Interaction(10)','creativity':'Creativity(10)','state_of_project':'State of Project(10)','dedication':'Dedication(10)','quality_of_report':'Quality of Report(20)','total':'Total(60)','names':'Names'})\n",
    "            conn.upsertEdgeDataFrame(sss_data, sourceVertexType='Student', edgeType='has_supervisor_score', targetVertexType='Supervisor_Score',from_id='Reg. Number', to_id='Reg. Number', attributes={})\n",
    "    try:\n",
    "        st.button('Send score sheet by mail', on_click=send_email, kwargs={'recipient': name_email_map[adviser_name], 'score_sheet': super_table.replace(0, \" \")})\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "with tab7:\n",
    "    try:\n",
    "        _ = conn.runInterpretedQuery(\n",
    "            \"\"\"\n",
    "            INTERPRET QUERY get_results() FOR GRAPH PMapp{\n",
    "\n",
    "             SumAccum<FLOAT> @results;\n",
    "\n",
    "             start = {Student.*};\n",
    "             result = SELECT s FROM start:s - (has_group_score) - Average_Group_Score:a\n",
    "                 ACCUM\n",
    "                     s.@results += a.total;\n",
    "             res = SELECT r FROM result:r - (has_supervisor_score) - Supervisor_Score:j\n",
    "                ACCUM\n",
    "                     r.@results += j.total\n",
    "                POST-ACCUM\n",
    "                     INSERT INTO Result VALUES (r.reg_number, r.@results, r.names),\n",
    "                     INSERT INTO has_result VALUES (r.reg_number Student, r.reg_number Result);\n",
    "\n",
    "             PRINT res;\n",
    "            }\n",
    "            \"\"\"\n",
    "            )\n",
    "        result = conn.getVertexDataFrame('Result', select='reg_number, names, overall_total')\n",
    "        result.drop(columns='v_id', inplace=True)\n",
    "        result.set_axis(['Reg. Number', 'Names', 'Score'], axis='columns', inplace=True)\n",
    "        result['Score'] = result['Score'].round(decimals = 0)\n",
    "        buff = np.array(result['Score'].values)\n",
    "        cond = np.isin(buff, [39, 49, 59, 69])\n",
    "        np.add(buff, 1, out=buff, where=cond)\n",
    "        result['Score'] = buff\n",
    "        cat = pd.cut(result['Score'], bins=[0, 40, 45, 50, 60, 70, 100], include_lowest=True, right=False, labels=['F','E','D','C','B','A'])\n",
    "        result['Grade'] = cat.tolist()\n",
    "        result = st.experimental_data_editor(result)\n",
    "        st.download_button(\n",
    "            label=\"Download Result as CSV\",\n",
    "            data=result.to_csv().encode('utf-8'),\n",
    "            file_name='Capstone Project Result.csv',\n",
    "            mime='text/csv',\n",
    "        )\n",
    "    except KeyError:\n",
    "        st.write(\"No result to process at the moment!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6446d0c4-a1a6-40aa-b810-922243e86049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile project-management-app.py \n",
    "\n",
    "# import streamlit as st\n",
    "# import pandas as pd\n",
    "# from pandas.errors import MergeError\n",
    "# import math\n",
    "# # import streamlit_authenticator as stauth\n",
    "\n",
    "# from googleapiclient.discovery import build\n",
    "# from google.oauth2 import service_account\n",
    "# # from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "# import json\n",
    "# import gspread \n",
    "# from gspread.exceptions import WorksheetNotFound, SpreadsheetNotFound\n",
    "\n",
    "# from st_aggrid import AgGrid, JsCode\n",
    "# from st_aggrid.grid_options_builder import GridOptionsBuilder\n",
    "\n",
    "# from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
    "\n",
    "# from annotated_text import annotated_text\n",
    "\n",
    "\n",
    "\n",
    "# checkbox_renderer = JsCode(\"\"\"\n",
    "# class CheckboxRenderer{\n",
    "\n",
    "#     init(params) {\n",
    "#         this.params = params;\n",
    "\n",
    "#         this.eGui = document.createElement('input');\n",
    "#         this.eGui.type = 'checkbox';\n",
    "#         this.eGui.checked = params.value;\n",
    "\n",
    "#         this.checkedHandler = this.checkedHandler.bind(this);\n",
    "#         this.eGui.addEventListener('click', this.checkedHandler);\n",
    "#     }\n",
    "\n",
    "#     checkedHandler(e) {\n",
    "#         let checked = e.target.checked;\n",
    "#         let colId = this.params.column.colId;\n",
    "#         this.params.node.setDataValue(colId, checked);\n",
    "#     }\n",
    "\n",
    "#     getGui(params) {\n",
    "#         return this.eGui;\n",
    "#     }\n",
    "\n",
    "#     destroy(params) {\n",
    "#     this.eGui.removeEventListener('click', this.checkedHandler);\n",
    "#     }\n",
    "# }//end class\n",
    "# \"\"\")\n",
    "\n",
    "# # st.session_state['authenticated_user'] = st.experimental_user.email\n",
    "\n",
    "# authenticated_user = st.experimental_user.email\n",
    "# st.write(authenticated_user)\n",
    "\n",
    "\n",
    "# save_master_copy = False\n",
    "# disable_available_adviser = True\n",
    "# not_admin = True\n",
    "\n",
    "# if authenticated_user in [\"eakinboboye@oauife.edu.ng\",  'test@localhost.com']:\n",
    "#     save_master_copy = True\n",
    "#     disable_available_adviser = False\n",
    "#     not_admin = False   \n",
    "\n",
    "# @st.experimental_singleton\n",
    "# class GoogleDriveService:\n",
    "#     def __init__(self):\n",
    "#         self._SCOPES=['https://www.googleapis.com/auth/drive', 'https://spreadsheets.google.com/feeds']\n",
    "#         # self.ServiceAccountCredentials = st.secrets['ServiceAccountCredentials']\n",
    "#         # st.write(st.secrets['ServiceAccountCredentials'])\n",
    "#         # self.jsonString = json.dumps({key:value for key, value in self.ServiceAccountCredentials.items()})\n",
    "        \n",
    "#     def build(self):\n",
    "#         # with open(data_file:=\"data.json\", \"w\") as jf:\n",
    "#         #     jf.write(self.jsonString)\n",
    "#         # creds = ServiceAccountCredentials.from_json_keyfile_name(data_file, self._SCOPES)\n",
    "#         creds = service_account.Credentials.from_service_account_info(st.secrets[\"ServiceAccountCredentials\"], scopes = self._SCOPES)\n",
    "#         service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "#         return service\n",
    "    \n",
    "# @st.experimental_singleton\n",
    "# def getFileListFromGDrive():\n",
    "#     selected_fields=\"files(id,name,webViewLink)\"\n",
    "#     g_drive_service=GoogleDriveService().build()\n",
    "#     list_file=g_drive_service.files().list(fields=selected_fields).execute()\n",
    "#     return {\"files\":list_file.get(\"files\")}\n",
    "\n",
    "# @st.experimental_singleton\n",
    "# def get_database(db_name, sheet):\n",
    "#         # Create a list of scope values to pass to the credentials object\n",
    "#         scope = ['https://spreadsheets.google.com/feeds',\n",
    "#                 'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "#         # Create a credentials object using the service account info and scope values\n",
    "#         credentials = service_account.Credentials.from_service_account_info(\n",
    "#                     st.secrets[\"ServiceAccountCredentialsSheet\"], scopes = scope)\n",
    "\n",
    "#         # Authorize the connection to Google Sheets using the credentials object\n",
    "#         gc = gspread.authorize(credentials)\n",
    "        \n",
    "#         try:\n",
    "#             # Open the Google Sheets document with the specified name\n",
    "#             sh = gc.open(db_name)\n",
    "#         except SpreadsheetNotFound:\n",
    "#             # Create the Google Sheets document with the specified name\n",
    "#             sh = gc.create(db_name)\n",
    "#         try:\n",
    "#             # Access the worksheet within the document with the specified name\n",
    "#             worksheet = sh.worksheet(sheet) \n",
    "#         except WorksheetNotFound:\n",
    "#             #Create the worksheet for the user\n",
    "#             worksheet = sh.add_worksheet(sheet, rows=1000, cols=50)\n",
    "            \n",
    "#         return worksheet\n",
    "\n",
    "# defense_worksheet = get_database(\"Defense Score Sheet\", authenticated_user)\n",
    "# supervisor_worksheet = get_database(\"Supervisor Score Sheet\", authenticated_user)\n",
    "\n",
    "# # preload_worksheet = get_database(\"defense_grouping_list\", 'Sheet1')\n",
    "\n",
    "# tab0, tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([\"Information Board\",\"Map Sheet\", \"Defense Group\", \"Score Sheets\", \"Upload Files\", \"Download Files\", \"Interactive Score Sheet\"])\n",
    "\n",
    "# with tab0:\n",
    "#     # user_name = [name for name in adviser if authenticated_user.find(name.split(\" \")[1].lower())==1][0]\n",
    "\n",
    "#     st.header(f'Project Management App')\n",
    "   \n",
    "#     st.markdown('''\n",
    "#                 _This tool was developed to help manage `EEE 501 & 502` essentially. The tool is to be employed by staff members only!_\n",
    "                \n",
    "#                 ''')\n",
    "    \n",
    "#     with st.expander('GUIDELINE FOR EEE 501/502 Report and Presentation Format', expanded=False):\n",
    "#         st.markdown('''\n",
    "#                     The reports and presentations must be organised thus:\n",
    "                    \n",
    "#                     1. `Introduction`: Clearly state the background to the problem\n",
    "\n",
    "#                     2. `Problem Statement`: What problem are you trying to solve and the significance of your solution\n",
    "\n",
    "#                     3. `Aim and specific objectives of the project`: What is the overall goal of your solution? What are the technical objectives required to achieve the solution?\n",
    "\n",
    "#                     4. `Literature Review`: What are the existing solutions to the problem and what are the limitations of these solutions? At least three (4) reviewed solutions should be explicitly presented in your project report. Existing reviewed solutions should be analyzed and summarized in tabular form on a single slide for your defense seminar listing the pros and cons. \n",
    "                    \n",
    "#                     5. `Methodology`: What is your solution? What are the step-by-step procedures used in the implementation of your solution? What are the fundamental engineering principles/theories used in your solution? Block Diagram(s)/Circuit Diagram(s)/Flow Charts of your solution or subsystem of your solution must be presented etc\n",
    "                    \n",
    "#                     6. `Current Status of Project and Preliminary Results`: What is the current status of the project? Do you have preliminary results? Like simulations etc. What are the implications of your solution? \n",
    "                    \n",
    "#                     7. `Future Plans`: What are your future plans? Discuss in terms of:\n",
    "#                         - deliverables\n",
    "#                         - timeline\n",
    "#                         - budget, etc.\n",
    "                    \n",
    "#                     ''')\n",
    "#     with st.expander('REQUIREMENTS', expanded=False):\n",
    "#         st.markdown('''\n",
    "#                     __Presentation slides__: students should prepare no more than fifteen (15) slides for the defense seminar\n",
    "                     \n",
    "#                     __Endorsement of project report__: supervisors must endorse all reports and preview slides before projects can be assessed by the panel during defense seminar.\n",
    "                   \n",
    "#                     __Report grading__: the student is required to revise the project report based on comments/suggestions/modifications by the assessors during the defense seminar. Revised project report and solution should be submitted to the supervisor for grading within one (1) week after your defense seminar.\n",
    "#                     ''')\n",
    "        \n",
    "#     with st.expander('HOW TO SAVE FILES INTO THE PROVIDED GOOGLE DRIVE', expanded=False):\n",
    "#         st.markdown('''\n",
    "#                     You are going to save `thesis and slides) into the provided [Google drive](https://drive.google.com/drive/folders/1XJ63r2NSU3Bsv4pCiI8z1F7FFO0ugsXA?usp=sharing) using the naming convention below:2 files` (\n",
    "                    \n",
    "#                     __Your thesis filed be named__xxxx/xxx-thesis.pdf: EEG/ shoul\n",
    "                    \n",
    "#                     __Your presentation file hould be named__/xxx-slides.pdf: EEG/xxxxs\n",
    "                    \n",
    "#                     > e.g. EEG/2006/059-thesis.pdf and EEG/2006/059-slides.pdf\n",
    "                    \n",
    "                    \n",
    "#                     __Note__: only pdf files are accepted!\n",
    "                    \n",
    "                    \n",
    "#                     Just put the 2 files into the `EEE 501/502 Project Management APP` folder. __Don't__ create a new folder please!\n",
    "#                     ''')\n",
    "\n",
    "    \n",
    "# @st.experimental_memo(ttl=300)\n",
    "# def load_data():\n",
    "#     # DATA_URL = \"2021 EEE 501-502.csv\"\n",
    "#     # return pd.read_csv(DATA_URL, nrows=1000)\n",
    "#     return get_as_dataframe(get_database(\"2021 EEE 501-502.csv\", 'Sheet1'), usecols=['Names','Reg. Number','Adviser','Option'])\n",
    "    \n",
    "# def drop_na(data):\n",
    "#     return data.dropna(how='all')\n",
    "\n",
    "# def sort_data(data):\n",
    "#     return data.sort_values(by=['Option'])\n",
    "\n",
    "# def set_ind(sorted_data):\n",
    "#     # return sorted_data.set_index(['Adviser'])\n",
    "#     return sorted_data.reset_index(drop=True)\n",
    "\n",
    "# data = load_data()\n",
    "# ddata = drop_na(data)\n",
    "# sorted_data = sort_data(ddata)\n",
    "# indexed_data = set_ind(sorted_data)\n",
    "\n",
    "# with tab1:\n",
    "#     # ssmap_data = indexed_data.loc[:,['Names', 'Reg. Number', 'Adviser']]\n",
    "    \n",
    "#     st.write('## EEE 501/502 Staff-Student Mapping Table')\n",
    "#     st.dataframe(indexed_data.loc[:,['Names', 'Reg. Number', 'Adviser']].sort_values(by=['Adviser']))\n",
    "\n",
    "# with tab2:\n",
    "    \n",
    "#     preload = st.checkbox('Load the allocation done by the admin', value=not_admin)\n",
    "    \n",
    "#     # grouping_table = []\n",
    "#     grouping_tables = pd.DataFrame({})\n",
    "    \n",
    "#     adviser = indexed_data['Adviser'].drop_duplicates().values\n",
    "    \n",
    "#     # user_name = [name for name in adviser if authenticated_user.find(name.split(\" \")[1].lower())==1][0]\n",
    "#     # st.write(usr_name)\n",
    "    \n",
    "#     available_adviser = st.multiselect(\n",
    "#     'Select the available staff members:', adviser, default=[], disabled=disable_available_adviser)\n",
    "    \n",
    "#     number_of_groups = st.number_input('Insert the number of groups you want', min_value=1, disabled=not_admin)\n",
    "    \n",
    "#     offset = 1\n",
    "#     groups = dict(zip(list(range(1,number_of_groups+1)),[available_adviser[i::number_of_groups] for i in range(number_of_groups)]))\n",
    "    \n",
    "#     students_total_no = len(indexed_data['Names'].to_list())\n",
    "#     try:\n",
    "#         students_ratio = dict(zip(list(range(1,number_of_groups+1)),[round((len(value)/len(available_adviser)) * students_total_no) for value in groups.values()]))\n",
    "#     except ZeroDivisionError:\n",
    "#         students_ratio = dict(zip(list(range(1,number_of_groups+1)),[0 for value in groups.values()]))\n",
    "\n",
    "#     if not sum(students_ratio.values())==students_total_no:\n",
    "#         diff = students_total_no - sum(students_ratio.values())\n",
    "#         students_ratio[1] += diff\n",
    "        \n",
    "#     indexed_data_copy = indexed_data.copy()\n",
    "    \n",
    "#     indexed_data_copy.set_index('Reg. Number',inplace=True)\n",
    "# #     try:\n",
    "# #         for key in groups.keys():\n",
    "# #             indexed_table = indexed_data_copy[eval(\"&\".join([f\"(indexed_data_copy.Adviser!='{i}')\" for i in groups[key]]))].sample(n=students_ratio[key], axis=0, random_state=2, replace=True)\n",
    "# #             indexed_data_copy.drop(indexed_table.index, inplace=True)\n",
    "# #             grouping_table.append(indexed_table.drop(columns='Option').reset_index(drop=True).assign(Group=key).assign(Staff=\" \".join(groups[key])).set_index(['Group']).drop_duplicates())\n",
    "\n",
    "# #         grouping_tables = pd.concat(grouping_table)\n",
    "# #     except ValueError:\n",
    "# #         pass\n",
    "# #     except SyntaxError:\n",
    "# #         pass\n",
    "\n",
    "#     random_state = st.slider('Vary randomness for best fit', 0, 100, 1)\n",
    "    \n",
    "#     student_div = dict(zip(list(range(1,number_of_groups+1)),[[] for i in range(number_of_groups)]))\n",
    "#     for student_reg in indexed_data_copy.sample(frac = 1, replace=False, random_state=random_state).index:\n",
    "#         for key in range(1,number_of_groups+1):\n",
    "#             if pd.isna(student_reg):\n",
    "#                 break\n",
    "#             try:\n",
    "#                 if student_reg not in indexed_data_copy[eval(\"^\".join([f\"(indexed_data_copy.Adviser=='{i}')\" for i in groups[key]]))].index and len(student_div[key])!=students_ratio[key]:\n",
    "#                     student_div[key].append(student_reg)\n",
    "#                     break\n",
    "#             except SyntaxError:\n",
    "#                 pass\n",
    "            \n",
    "#     if not preload:\n",
    "        \n",
    "#         grouping_tables = pd.concat(grouping_table:=[indexed_data_copy.loc[value].drop(columns='Option').assign(Group=key).assign(Staff=\" \".join(groups[key])) for key,value in student_div.items()])\n",
    "\n",
    "#         if pd.concat([indexed_data.dropna().Names, grouping_tables.Names]).drop_duplicates(keep=False).shape[0] > 1:\n",
    "#             st.write('## Unallocated Students:', pd.concat([indexed_data.dropna().Names, grouping_tables.Names]).drop_duplicates(keep=False))\n",
    "#         elif pd.concat([indexed_data.dropna().Names, grouping_tables.Names]).drop_duplicates(keep=False).shape[0] == 1:\n",
    "#             reg_number = indexed_data.iloc[pd.concat([indexed_data.dropna().Names, grouping_tables.Names]).drop_duplicates(keep=False).index[0]]['Reg. Number']\n",
    "#             student_div[number_of_groups].append(student_div[1].pop())\n",
    "#             student_div[1].append(reg_number)\n",
    "\n",
    "#             grouping_tables = pd.concat(grouping_table:=[indexed_data_copy.loc[value].drop(columns='Option').assign(Group=key).assign(Staff=\" \".join(groups[key])) for key,value in student_div.items()])\n",
    "    \n",
    "#     else:\n",
    "#         try:\n",
    "#             grouping_tables = get_as_dataframe(get_database(\"defense_grouping_list.csv\", 'Sheet1'),usecols=['Reg. Number','Names','Adviser','Group','Staff']).dropna(how='all')#pd.read_csv('defense_grouping_list.csv', nrows=1000)\n",
    "#             grouping_tables.set_index('Reg. Number',inplace=True)\n",
    "#             grouping_table = [grouping_tables.loc[indices,:] for indices in grouping_tables.groupby('Group').groups.values()]\n",
    "#         except FileNotFoundError:\n",
    "#             grouping_tables = pd.DataFrame({})\n",
    "        \n",
    "#     st.write('## Defense Grouping List')\n",
    "#     st.dataframe(grouping_tables)\n",
    "    \n",
    "#     if save_master_copy and not grouping_tables.empty:\n",
    "#         st.button('save admin copy', on_click=set_with_dataframe(get_database(\"defense_grouping_list.csv\", 'Sheet1'), grouping_tables, include_index=True))\n",
    "    \n",
    "#     @st.experimental_memo\n",
    "#     def convert_df(df):\n",
    "#         # IMPORTANT: Cache the conversion to prevent computation on every rerun\n",
    "#         return df.to_csv().encode('utf-8')\n",
    "\n",
    "#     if not grouping_tables.empty:\n",
    "#         csv = convert_df(grouping_tables)\n",
    "\n",
    "#         st.download_button(\n",
    "#             label=\"Download list as CSV\",\n",
    "#             data=csv,\n",
    "#             file_name='defense_grouping_list.csv',\n",
    "#             mime='text/csv',\n",
    "#         )\n",
    "    \n",
    "# with tab3:\n",
    "#     table_to_edit = pd.DataFrame({})\n",
    "    \n",
    "#     try:\n",
    "#         for i,table in enumerate(grouping_table):\n",
    "#             table['Presentation(10)'] = \"\"\n",
    "#             table['Understanding (10)'] = \"\"\n",
    "#             table['Creativity (10)'] = \"\"\n",
    "#             table['Answer to Questions (5)'] = \"\"\n",
    "#             table['Appearance (3)'] = \"\"\n",
    "#             table['Attendance (2)'] = \"\"\n",
    "#             table['Total (40)'] = \"\"\n",
    "            \n",
    "#             staff_list = table['Staff'].drop_duplicates().values\n",
    "                        \n",
    "#             table.drop(columns=['Staff', 'Adviser', 'Group'], inplace=True)\n",
    "#             table.reset_index(drop=False, inplace=True)\n",
    "            \n",
    "#             st.write(f'Group {i+1} Score Sheet: {staff_list[0]}')\n",
    "#             st.dataframe(table)\n",
    "            \n",
    "#             if 1 in [authenticated_user.find(name.lower()) for name in staff_list[0].split(\" \") if not name.endswith('.')]:\n",
    "                \n",
    "#                 table_to_edit = table\n",
    "                \n",
    "#                 # st.session_state['data_shape'] = table.shape\n",
    "                       \n",
    "#             csv = convert_df(table)\n",
    "\n",
    "#             st.download_button(\n",
    "#                 label=f\"Download Group {i+1} Score sheet as CSV\",\n",
    "#                 data=csv,\n",
    "#                 file_name=f'Group {i+1} Score sheet.csv',\n",
    "#                 mime='text/csv',\n",
    "#             )\n",
    "#     except (NameError, IndexError):\n",
    "#         st.write(f'### You have not created the defense grouping list yet!')\n",
    "#     # except IndexError:\n",
    "        \n",
    "# with tab4:\n",
    "#     st.write('### Upload a PDF file against your registration number')    \n",
    "    \n",
    "#     option = st.selectbox(\n",
    "#     f'Select your registration number:',\n",
    "#     [student for student in grouping_tables.index], key=1)\n",
    "    \n",
    "#     st.write(f'You are in Group {grouping_tables.loc[option].Group if option else \"\"}')\n",
    "    \n",
    "#     project_title = st.text_area('Enter the title of your project here...')\n",
    "\n",
    "#     Upload=st.file_uploader(\"Choose a PDF file\", accept_multiple_files=True)\n",
    "    \n",
    "# with tab5:\n",
    "#     files_to_download = getFileListFromGDrive()\n",
    "    \n",
    "#     col1, col2, col3 = st.columns([2,4,4])\n",
    "    \n",
    "#     with col1:\n",
    "#         filtar = st.selectbox(\n",
    "#         'Filter with groups',\n",
    "#         [f'Group {grp}' for grp in groups.keys()] if not preload else [f'Group {grp}' for grp in range(1,len(grouping_table)+1)]\n",
    "#         )\n",
    "        \n",
    "        \n",
    "#     with col2:\n",
    "#         opt = st.selectbox(\n",
    "#         f'Select a registration number:',\n",
    "#         [student for student in grouping_tables.index if grouping_tables.loc[student].Group == int(filtar.split(\" \")[1])], key=2)\n",
    "        \n",
    "#     with col3:\n",
    "#         # placeholder = st.empty()\n",
    "        \n",
    "#         try:\n",
    "#             file = st.selectbox(\n",
    "#             f'Select the file to download:',\n",
    "#             [file['name'] for file in files_to_download['files'] if file['name'].startswith(opt.replace('/','_'))], key=3)#!='EEE 501/502 Project Management APP'], key=3)\n",
    "\n",
    "#             data =  [f['webViewLink'] for f in files_to_download['files'] if f['name'].startswith(file)]\n",
    "            \n",
    "#             st.markdown(f\"[Open {file.split('-')[1]} for {file.split('-')[0]}]({data[0]})\", unsafe_allow_html=True)\n",
    "\n",
    "#             # if st.button(f\"Open {file.split('-')[1]} for {file.split('-')[0]}\"):\n",
    "#                 # st.write(data[0])\n",
    "#                 # webbrowser.open(data[0])\n",
    "# #             data_file = urlopen(data)\n",
    "                \n",
    "# #             st.write(data_file.fp.read())\n",
    "            \n",
    "#             # Download=st.download_button(label=f\"Download {file.split('-')[1]} for {file.split('-')[0]}\", data=b'', file_name=f'{file}',mime='application/pdf')\n",
    "#         except (AttributeError,TypeError):\n",
    "#             pass\n",
    "#         except IndexError:\n",
    "#             annotated_text(\n",
    "#                             \"This \",\n",
    "#                             (\"student\", f\"{opt}\", \"#8ef\"),\n",
    "#                             \" might \",\n",
    "#                             (\"not\", \"#8bf\"),\n",
    "#                             \"have\",\n",
    "#                             (\"formatted\", \"#afa\"),\n",
    "#                             \"the\",\n",
    "#                             (\"files:\", f\"{file}\", \"#fea\"),\n",
    "#                             \"properly \",\n",
    "#                             \"hence \",\n",
    "#                             \"the submission is\",\n",
    "#                             (\"invalid!\", \"#8ef\"),\n",
    "\n",
    "#                         )\n",
    "#             # placeholder.text('The student might not have formatted the files properly, hence the submission is invalid!')\n",
    "# #     with st.expander(f'Question Pool for {opt}'):\n",
    "# #         with st.form('Add Questions for a Student') as f:\n",
    "# #             question_table = pd.DataFrame({'Reg. Number':[opt],'Question':[''],'Remark':[False]})\n",
    "# #             # question_pool = get_as_dataframe(get_database(\"Question-Pool\", st.session_state.authenticated_user),usecols=['Reg. Number','Question','Remark']).dropna(how='all')\n",
    "\n",
    "# #             gob = GridOptionsBuilder.from_dataframe(question_table)\n",
    "# #             gob.configure_column('Remark', editable=True, cellRenderer=checkbox_renderer)\n",
    "# #             gob.configure_default_column(editable=True)\n",
    "# #             gridoptions = gob.build()\n",
    "# #             AgGrid(question_table,\n",
    "# #                     gridOptions = gridoptions, \n",
    "# #                     editable=True,\n",
    "# #                     allow_unsafe_jscode = True, \n",
    "# #                     theme = 'balham',\n",
    "# #                     height = 200,\n",
    "# #                     fit_columns_on_grid_load = True)\n",
    "# #             st.form_submit_button(\"Save\")\n",
    "        \n",
    "# with tab6:\n",
    "#     # with st.expander('Defense Score Sheet', expanded=False):\n",
    "#     try:\n",
    "#         # int_table = get_as_dataframe(defense_worksheet, usecols=table_to_edit.columns).dropna(how='all')#nrows=st.session_state['data_shape'][0], usecols=[i for i in range(st.session_state['data_shape'][1])])\n",
    "#         # try:\n",
    "#         #     table_to_edit = table_to_edit.merge(int_table)\n",
    "#         # except (MergeError, ValueError):\n",
    "#         #     pass\n",
    "\n",
    "#         # Create a GridOptionsBuilder object from our DataFrame\n",
    "#         gd = GridOptionsBuilder.from_dataframe(table_to_edit)\n",
    "\n",
    "#         # Configure the default column to be editable\n",
    "#         # sets the editable option to True for all columns\n",
    "#         gd.configure_default_column(editable=True)\n",
    "\n",
    "#         gridoptions = gd.build()\n",
    "\n",
    "#         with st.form('Defense Score Sheet') as f:\n",
    "#             response = AgGrid(table_to_edit,\n",
    "#                             gridOptions = gridoptions, \n",
    "#                             editable=True,\n",
    "#                             theme = 'balham',\n",
    "#                             height = 200,\n",
    "#                             fit_columns_on_grid_load = True)\n",
    "#             st.write(\" *Note: Don't forget to hit enter ↩ on new entry.*\")\n",
    "#             st.form_submit_button(\"Save\", on_click=set_with_dataframe(defense_worksheet, response['data']))\n",
    "#             # st.success(\"Updated to Database \", icon=\"✅\")\n",
    "#     except KeyError:\n",
    "#         st.write('#### Make sure that the students are allocated into groups first or sign in to use the service!')\n",
    "            \n",
    "# #     with st.expander('Supervisor Score Sheet', expanded=False):\n",
    "# #         try:\n",
    "# #             super_table = indexed_data_copy[indexed_data_copy.Adviser==[name for name in adviser if authenticated_user.find(name.split(\" \")[1].lower())==1][0]]\n",
    "# #             super_table = super_table[super_table.columns.intersection(['Names', 'Reg. Number'])].assign(Title=\"\").assign(Grade=\"\")\n",
    "# #             try:\n",
    "# #                 super_table_remote = get_as_dataframe(supervisor_worksheet, usecols=['Reg. Number','Names', 'Title', 'Grade']).dropna(how='all')\n",
    "# #                 super_table = super_table.merge(super_table_remote)\n",
    "# #             except:\n",
    "# #                 pass\n",
    "# #             # Create a GridOptionsBuilder object from our DataFrame\n",
    "# #             gd = GridOptionsBuilder.from_dataframe(super_table)\n",
    "\n",
    "# #             # Configure the default column to be editable\n",
    "# #             # sets the editable option to True for all columns\n",
    "# #             gd.configure_default_column(editable=True)\n",
    "\n",
    "# #             gridoptions = gd.build()\n",
    "\n",
    "# #             with st.form('Supervisor Score Sheet') as f:\n",
    "# #                 response = AgGrid(super_table,\n",
    "# #                                 gridOptions = gridoptions, \n",
    "# #                                 editable=True,\n",
    "# #                                 theme = 'balham',\n",
    "# #                                 height = 200,\n",
    "# #                                 fit_columns_on_grid_load = True)\n",
    "# #                 st.write(\" *Note: Don't forget to hit enter ↩ on new entry.*\")\n",
    "# #                 st.form_submit_button(\"Save\", on_click=set_with_dataframe(supervisor_worksheet, response['data']))\n",
    "# #         except:\n",
    "# #             st.write('#### You need to sign in to use this service!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cce2fd3-0546-4e29-9ad9-a308f82bbdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.download_button(label=f\"Download file\",data=csv,file_name=f'Score sheet.csv',mime='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373bc172-890d-40f7-b48e-29f6b5e94908",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_div = dict(zip(list(range(1,4+1)),[[] for i in range(4)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "314bb139-37fb-4ccf-9002-02bb89e62ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([[], [], [], []])"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_div.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ae520abf-2cbb-40a5-b367-6779199f83b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_students():\n",
    "    for key in groups.keys():\n",
    "        dff2.loc[groups[key],:]['Names'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a469c158-1515-49e2-9f6a-780ff78b1b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = \"2021 EEE 501-502.csv\"\n",
    "dff = pd.read_csv(DATA_URL, nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e33b5c6a-c4e9-4dad-b54b-09311177eea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Reg. Number</th>\n",
       "      <th>Adviser</th>\n",
       "      <th>Option</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OMOLOYIN SAMSON OLUWATOSIN</td>\n",
       "      <td>EEG/2016/058</td>\n",
       "      <td>Mr. Akinboboye</td>\n",
       "      <td>Instr &amp; contr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OGBODO ENE VICTORIA</td>\n",
       "      <td>EEG/2016/045</td>\n",
       "      <td>Mr. Akinboboye</td>\n",
       "      <td>Instr &amp; contr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OGUNSOLU OLUWASEUNFUNMI EMMAMUEL</td>\n",
       "      <td>EEG/2016/047</td>\n",
       "      <td>Mr. Akinboboye</td>\n",
       "      <td>Instr &amp; contr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHRISTIAN JOSHUA OPEYEMI</td>\n",
       "      <td>EEG/2016/018</td>\n",
       "      <td>Mr. Akinboboye</td>\n",
       "      <td>Instr &amp; contr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IBRAHIM FAROUK AYODEJI</td>\n",
       "      <td>EEG/2016/092</td>\n",
       "      <td>Mr. Akinboboye</td>\n",
       "      <td>Instr &amp; contr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>KUKU TEMITOPE</td>\n",
       "      <td>EEG/2017/132</td>\n",
       "      <td>Dr. Yesufu</td>\n",
       "      <td>Comms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>ONWUANAKU GREGORY</td>\n",
       "      <td>EEG/2016/061</td>\n",
       "      <td>Dr. Yesufu</td>\n",
       "      <td>Comms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>AFOLABI GODSPOWER OLAMIDE</td>\n",
       "      <td>EEG/2016/008</td>\n",
       "      <td>Dr. Yesufu</td>\n",
       "      <td>Comms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dr. Obayiuwana</td>\n",
       "      <td>Comms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dr. Jubril</td>\n",
       "      <td>Instr &amp; contr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Names  ...         Option\n",
       "0          OMOLOYIN SAMSON OLUWATOSIN  ...  Instr & contr\n",
       "1                 OGBODO ENE VICTORIA  ...  Instr & contr\n",
       "2    OGUNSOLU OLUWASEUNFUNMI EMMAMUEL  ...  Instr & contr\n",
       "3            CHRISTIAN JOSHUA OPEYEMI  ...  Instr & contr\n",
       "4              IBRAHIM FAROUK AYODEJI  ...  Instr & contr\n",
       "..                                ...  ...            ...\n",
       "111                     KUKU TEMITOPE  ...          Comms\n",
       "112                 ONWUANAKU GREGORY  ...          Comms\n",
       "113         AFOLABI GODSPOWER OLAMIDE  ...          Comms\n",
       "114                               NaN  ...          Comms\n",
       "115                               NaN  ...  Instr & contr\n",
       "\n",
       "[116 rows x 4 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "666d07a3-1aad-4542-b717-ab575dcf8ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = dff.groupby('Adviser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "65904ca5-37d8-46a4-9e01-477a7e207e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Names', 'Reg. Number', 'Adviser', 'Option'], dtype=object)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "f75124d8-bfa1-48a8-a12e-06cdeabcdb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "adviser = dff['Adviser'].drop_duplicates().values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "0068b29e-e55d-4120-bb37-0cbc3939eb90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Reg. Number</th>\n",
       "      <th>Adviser</th>\n",
       "      <th>Option</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OMOLOYIN SAMSON OLUWATOSIN</td>\n",
       "      <td>EEG/2016/058</td>\n",
       "      <td>Mr. Akinboboye</td>\n",
       "      <td>Instr &amp; contr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OGBODO ENE VICTORIA</td>\n",
       "      <td>EEG/2016/045</td>\n",
       "      <td>Mr. Akinboboye</td>\n",
       "      <td>Instr &amp; contr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OGUNSOLU OLUWASEUNFUNMI EMMAMUEL</td>\n",
       "      <td>EEG/2016/047</td>\n",
       "      <td>Mr. Akinboboye</td>\n",
       "      <td>Instr &amp; contr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHRISTIAN JOSHUA OPEYEMI</td>\n",
       "      <td>EEG/2016/018</td>\n",
       "      <td>Mr. Akinboboye</td>\n",
       "      <td>Instr &amp; contr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IBRAHIM FAROUK AYODEJI</td>\n",
       "      <td>EEG/2016/092</td>\n",
       "      <td>Mr. Akinboboye</td>\n",
       "      <td>Instr &amp; contr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OGUNDIPE SAMUEL TEMITAYO</td>\n",
       "      <td>EEG/2016/046</td>\n",
       "      <td>Mr. Akinboboye</td>\n",
       "      <td>Instr &amp; contr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ALABI FADLULLAH</td>\n",
       "      <td>EEG/2017/113</td>\n",
       "      <td>Mr. Akinboboye</td>\n",
       "      <td>Instr &amp; contr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Names  ...         Option\n",
       "0        OMOLOYIN SAMSON OLUWATOSIN  ...  Instr & contr\n",
       "1               OGBODO ENE VICTORIA  ...  Instr & contr\n",
       "2  OGUNSOLU OLUWASEUNFUNMI EMMAMUEL  ...  Instr & contr\n",
       "3          CHRISTIAN JOSHUA OPEYEMI  ...  Instr & contr\n",
       "4            IBRAHIM FAROUK AYODEJI  ...  Instr & contr\n",
       "5          OGUNDIPE SAMUEL TEMITAYO  ...  Instr & contr\n",
       "6                   ALABI FADLULLAH  ...  Instr & contr\n",
       "\n",
       "[7 rows x 4 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff[dff.Adviser==[name for name in adviser if 'eakinboboye@oauife.edu.ng'.find(name.split(\" \")[1].lower())==1][0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "60e89a6a-ad6f-4205-9d54-9c510fe3b600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BAKARE MOSHOOD ABIOLA'"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff1.dropna().Names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "b520510c-c7a3-4da4-9050-28a9c53f2943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Adviser</th>\n",
       "      <th>Option</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reg. Number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EEG/2016/010</th>\n",
       "      <td>AKINTUNDE ISRAEL TOLULOPE</td>\n",
       "      <td>Dr. Fisusi</td>\n",
       "      <td>Comms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG/2017/117</th>\n",
       "      <td>BAKARE MOSHOOD ABIOLA</td>\n",
       "      <td>Dr. Fisusi</td>\n",
       "      <td>Comms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG/2016/027</th>\n",
       "      <td>FAREMI SAHEED AKINPELUMI</td>\n",
       "      <td>Dr. Fisusi</td>\n",
       "      <td>Comms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG/2016/061</th>\n",
       "      <td>ONWUANAKU GREGORY</td>\n",
       "      <td>Dr. Yesufu</td>\n",
       "      <td>Comms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Names     Adviser Option\n",
       "Reg. Number                                               \n",
       "EEG/2016/010  AKINTUNDE ISRAEL TOLULOPE  Dr. Fisusi  Comms\n",
       "EEG/2017/117      BAKARE MOSHOOD ABIOLA  Dr. Fisusi  Comms\n",
       "EEG/2016/027   FAREMI SAHEED AKINPELUMI  Dr. Fisusi  Comms\n",
       "EEG/2016/061          ONWUANAKU GREGORY  Dr. Yesufu  Comms"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff1.loc[['EEG/2016/010', 'EEG/2017/117', 'EEG/2016/027', 'EEG/2016/061']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "701e0112-f46d-4cc1-8099-a97f4b00a344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EEG/2016/010', 'EEG/2017/117', 'EEG/2016/027', 'EEG/2016/061',\n",
       "       'EEG/2016/022', 'EEG/2016/087', 'EEG/2017/123', 'EEG/2016/062',\n",
       "       'EEG/2016/066', 'EEG/2017/133', 'EEG/2016/107', 'EEG/2017/132',\n",
       "       'EEG/2017/114', 'EEG/2016/067', 'EEG/2016/008'],\n",
       "      dtype='object', name='Reg. Number')"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff1[(dff1.Adviser=='Dr. Fisusi')^(dff1.Adviser=='Dr. Yesufu')].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "6d9ea7f6-6cce-4a24-9014-7a939e7dd077",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff1.set_index('Adviser', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "2ea29ea0-f14e-4c31-8743-cc3dc787f8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Reg. Number</th>\n",
       "      <th>Option</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adviser</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dr. Akinwale</th>\n",
       "      <td>DANIEL TOBI FRANCIS</td>\n",
       "      <td>EEG/2016/091</td>\n",
       "      <td>Instr &amp; contr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr. Akinwale</th>\n",
       "      <td>OKWUNZE CHIAGOZIE KELVIN</td>\n",
       "      <td>EEG/2016/049</td>\n",
       "      <td>Instr &amp; contr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr. Akinwale</th>\n",
       "      <td>TAIWO ABDULMALIK ADEDAYO</td>\n",
       "      <td>EEG/2016/101</td>\n",
       "      <td>Instr &amp; contr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr. Akinwale</th>\n",
       "      <td>OLADOSU MOSES ANUOLUWAPO</td>\n",
       "      <td>EEG/2016/052</td>\n",
       "      <td>Instr &amp; contr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr. Akinwale</th>\n",
       "      <td>OYETUNJI ISRAEL TOLUWANIMI</td>\n",
       "      <td>EEG/2016/065</td>\n",
       "      <td>Instr &amp; contr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr. Olorunniwo</th>\n",
       "      <td>OTI JOEL CHUKWUEMEKA</td>\n",
       "      <td>EEG/2016/099</td>\n",
       "      <td>Instr &amp; contr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr. Olorunniwo</th>\n",
       "      <td>LARINDE OLADOSU MORAKINYO</td>\n",
       "      <td>EEG/2016/040</td>\n",
       "      <td>Instr &amp; contr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr. Olorunniwo</th>\n",
       "      <td>OLADOSU ABIMBOLA BABAJIDE</td>\n",
       "      <td>EEG/2016/053</td>\n",
       "      <td>Instr &amp; contr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr. Olorunniwo</th>\n",
       "      <td>IBEH CHIBUNA KENNETH</td>\n",
       "      <td>EEG/2016/029</td>\n",
       "      <td>Instr &amp; contr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr. Olorunniwo</th>\n",
       "      <td>ONIWAYA PRECIOUS OLUWASHINA</td>\n",
       "      <td>EEG/2016/060</td>\n",
       "      <td>Instr &amp; contr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Names   Reg. Number         Option\n",
       "Adviser                                                                 \n",
       "Dr. Akinwale            DANIEL TOBI FRANCIS  EEG/2016/091  Instr & contr\n",
       "Dr. Akinwale       OKWUNZE CHIAGOZIE KELVIN  EEG/2016/049  Instr & contr\n",
       "Dr. Akinwale       TAIWO ABDULMALIK ADEDAYO  EEG/2016/101  Instr & contr\n",
       "Dr. Akinwale       OLADOSU MOSES ANUOLUWAPO  EEG/2016/052  Instr & contr\n",
       "Dr. Akinwale     OYETUNJI ISRAEL TOLUWANIMI  EEG/2016/065  Instr & contr\n",
       "...                                     ...           ...            ...\n",
       "Mr. Olorunniwo         OTI JOEL CHUKWUEMEKA  EEG/2016/099  Instr & contr\n",
       "Mr. Olorunniwo    LARINDE OLADOSU MORAKINYO  EEG/2016/040  Instr & contr\n",
       "Mr. Olorunniwo    OLADOSU ABIMBOLA BABAJIDE  EEG/2016/053  Instr & contr\n",
       "Mr. Olorunniwo         IBEH CHIBUNA KENNETH  EEG/2016/029  Instr & contr\n",
       "Mr. Olorunniwo  ONIWAYA PRECIOUS OLUWASHINA  EEG/2016/060  Instr & contr\n",
       "\n",
       "[103 rows x 3 columns]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff1.loc[diff1.index.difference('Dr. Fisusi',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "90319bf0-a816-43f9-a356-e38b85a58ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test.py\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "# Everything is accessible via the st.secrets dict:\n",
    "\n",
    "st.write(st.secrets['credentials'],\n",
    "    st.secrets['cookie']['name'],\n",
    "    st.secrets['cookie']['key'],\n",
    "    st.secrets['cookie']['expiry_days'],\n",
    "    st.secrets['preauthorized'])\n",
    "# st.write(\"DB password:\", st.secrets[\"db_password\"])\n",
    "# st.write(\"My cool secrets:\", st.secrets[\"my_cool_secrets\"][\"things_i_like\"])\n",
    "\n",
    "# And the root-level secrets are also accessible as environment variables:\n",
    "\n",
    "# import os\n",
    "\n",
    "# st.write(\n",
    "#     \"Has environment variables been set:\",\n",
    "#     os.environ[\"db_username\"] == st.secrets[\"db_username\"],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fe37ac8-9356-4304-a178-23003ea3bc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mServiceAccountCredentials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mservice_account_email\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msigner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mscopes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprivate_key_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclient_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtoken_uri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'https://oauth2.googleapis.com/token'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrevoke_uri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'https://oauth2.googleapis.com/revoke'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Service Account credential for OAuth 2.0 signed JWT grants.\n",
       "\n",
       "Supports\n",
       "\n",
       "* JSON keyfile (typically contains a PKCS8 key stored as\n",
       "  PEM text)\n",
       "* ``.p12`` key (stores PKCS12 key and certificate)\n",
       "\n",
       "Makes an assertion to server using a signed JWT assertion in exchange\n",
       "for an access token.\n",
       "\n",
       "This credential does not require a flow to instantiate because it\n",
       "represents a two legged flow, and therefore has all of the required\n",
       "information to generate and refresh its own access tokens.\n",
       "\n",
       "Args:\n",
       "    service_account_email: string, The email associated with the\n",
       "                           service account.\n",
       "    signer: ``crypt.Signer``, A signer which can be used to sign content.\n",
       "    scopes: List or string, (Optional) Scopes to use when acquiring\n",
       "            an access token.\n",
       "    private_key_id: string, (Optional) Private key identifier. Typically\n",
       "                    only used with a JSON keyfile. Can be sent in the\n",
       "                    header of a JWT token assertion.\n",
       "    client_id: string, (Optional) Client ID for the project that owns the\n",
       "               service account.\n",
       "    user_agent: string, (Optional) User agent to use when sending\n",
       "                request.\n",
       "    token_uri: string, URI for token endpoint. For convenience defaults\n",
       "               to Google's endpoints but any OAuth 2.0 provider can be\n",
       "               used.\n",
       "    revoke_uri: string, URI for revoke endpoint.  For convenience defaults\n",
       "               to Google's endpoints but any OAuth 2.0 provider can be\n",
       "               used.\n",
       "    kwargs: dict, Extra key-value pairs (both strings) to send in the\n",
       "            payload body when making an assertion.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Constructor for AssertionFlowCredentials.\n",
       "\n",
       "Args:\n",
       "    assertion_type: string, assertion type that will be declared to the\n",
       "                    auth server\n",
       "    user_agent: string, The HTTP User-Agent to provide for this\n",
       "                application.\n",
       "    token_uri: string, URI for token endpoint. For convenience defaults\n",
       "               to Google's endpoints but any OAuth 2.0 provider can be\n",
       "               used.\n",
       "    revoke_uri: string, URI for revoke endpoint.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/tf/lib/python3.9/site-packages/oauth2client/service_account.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     _JWTAccessCredentials"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ServiceAccountCredentials?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b92698fc-18d0-41d6-a5fd-7ab21257e76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from googleapiclient.discovery import build\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "import tomli\n",
    "import json\n",
    "\n",
    "with open(\".streamlit/secrets.toml\", mode=\"rb\") as fp:\n",
    "    config = tomli.load(fp)\n",
    "    credential = config['ServiceAccountCredentials']\n",
    "\n",
    "    \n",
    "class GoogleDriveService:\n",
    "    def __init__(self):\n",
    "        self._SCOPES=['https://www.googleapis.com/auth/drive']\n",
    "        # self.ServiceAccountCredentials = st.secrets['ServiceAccountCredentials']\n",
    "        self.jsonString = json.dumps(credential)\n",
    "        \n",
    "    def build(self):\n",
    "        with open(data_file:=\"data.json\", \"w\") as jf:\n",
    "            jf.write(self.jsonString)\n",
    "        creds = ServiceAccountCredentials.from_json_keyfile_name(data_file, self._SCOPES)\n",
    "        service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "        return service\n",
    "\n",
    "def getFileListFromGDrive():\n",
    "    selected_fields=\"files(id,name,webViewLink)\"\n",
    "    g_drive_service=GoogleDriveService().build()\n",
    "    list_file=g_drive_service.files().list(fields=selected_fields).execute()\n",
    "    return {\"files\":list_file.get(\"files\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f66bf681-4698-4daf-9f1e-238e4f9db1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread \n",
    "from gspread.exceptions import WorksheetNotFound, SpreadsheetNotFound\n",
    "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b7601ec2-41bf-412e-9e1b-ecf62b4cb783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_database(folder_id, db_name, sheet):\n",
    "        \n",
    "        # Authorize the connection to Google Sheets using the credentials object\n",
    "        gc = gspread.authorize(credentials)\n",
    "        \n",
    "        #try:\n",
    "            # Open the Google Sheets document with the specified name\n",
    "        sh = gc.open(db_name, folder_id)\n",
    "        #except SpreadsheetNotFound:\n",
    "            # Create the Google Sheets document with the specified name\n",
    "            #sh = gc.create(db_name, folder_id)\n",
    "            # sh.share('eakinboboye@oauife.edu.ng', perm_type='user', role='editor')\n",
    "        #try:\n",
    "            # Access the worksheet within the document with the specified name\n",
    "        worksheet = sh.worksheet(sheet) \n",
    "        #except WorksheetNotFound:\n",
    "            #Create the worksheet for the user\n",
    "            #worksheet = sh.add_worksheet(sheet, rows=1000, cols=50)\n",
    "            \n",
    "        return worksheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1e8b98b6-3425-4441-a9f6-e3358d435a09",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Usecols do not match columns, columns expected but not found: ['Reg. Number', 'Adviser', 'Option', 'Names']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/pandas/io/parsers.py:2789\u001b[0m, in \u001b[0;36mPythonParser._handle_usecols\u001b[0;34m(self, columns, usecols_key)\u001b[0m\n\u001b[1;32m   2788\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2789\u001b[0m     col_indices\u001b[38;5;241m.\u001b[39mappend(\u001b[43musecols_key\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2790\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: 'Reg. Number' is not in list",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_as_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_database\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1EJQyD0NghC1lxalJCWINQYvqAZdnGDve\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGroup Score Sheet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSheet1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNames\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReg. Number\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAdviser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOption\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/gspread_dataframe.py:190\u001b[0m, in \u001b[0;36mget_as_dataframe\u001b[0;34m(worksheet, evaluate_formulas, **options)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03mReturns the worksheet contents as a DataFrame.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m:returns: pandas.DataFrame\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m all_values \u001b[38;5;241m=\u001b[39m _get_all_values(worksheet, evaluate_formulas)\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTextParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mread(options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/pandas/io/parsers.py:2229\u001b[0m, in \u001b[0;36mTextParser\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m   2173\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2174\u001b[0m \u001b[38;5;124;03mConverts lists of lists/tuples into DataFrames with proper type inference\u001b[39;00m\n\u001b[1;32m   2175\u001b[0m \u001b[38;5;124;03mand optional (e.g. string to datetime) conversion. Also enables iterating\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2226\u001b[0m \u001b[38;5;124;03m    .. versionchanged:: 1.2\u001b[39;00m\n\u001b[1;32m   2227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2228\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 2229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/pandas/io/parsers.py:819\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwds:\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 819\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/pandas/io/parsers.py:1050\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1046\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1047\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown engine: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (valid options are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmapping\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1048\u001b[0m     )\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;66;03m# error: Too many arguments for \"ParserBase\"\u001b[39;00m\n\u001b[0;32m-> 1050\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/pandas/io/parsers.py:2310\u001b[0m, in \u001b[0;36mPythonParser.__init__\u001b[0;34m(self, f, **kwds)\u001b[0m\n\u001b[1;32m   2304\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_col_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2305\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2306\u001b[0m     (\n\u001b[1;32m   2307\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns,\n\u001b[1;32m   2308\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_original_columns,\n\u001b[1;32m   2309\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols,\n\u001b[0;32m-> 2310\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2311\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   2312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/pandas/io/parsers.py:2723\u001b[0m, in \u001b[0;36mPythonParser._infer_columns\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2721\u001b[0m         columns \u001b[38;5;241m=\u001b[39m [names]\n\u001b[1;32m   2722\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2723\u001b[0m         columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_usecols\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2724\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2725\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/pandas/io/parsers.py:2791\u001b[0m, in \u001b[0;36mPythonParser._handle_usecols\u001b[0;34m(self, columns, usecols_key)\u001b[0m\n\u001b[1;32m   2789\u001b[0m         col_indices\u001b[38;5;241m.\u001b[39mappend(usecols_key\u001b[38;5;241m.\u001b[39mindex(col))\n\u001b[1;32m   2790\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m-> 2791\u001b[0m         \u001b[43m_validate_usecols_names\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2792\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2793\u001b[0m     col_indices\u001b[38;5;241m.\u001b[39mappend(col)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/pandas/io/parsers.py:1162\u001b[0m, in \u001b[0;36m_validate_usecols_names\u001b[0;34m(usecols, names)\u001b[0m\n\u001b[1;32m   1160\u001b[0m missing \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m usecols \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m names]\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsecols do not match columns, columns expected but not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1164\u001b[0m     )\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m usecols\n",
      "\u001b[0;31mValueError\u001b[0m: Usecols do not match columns, columns expected but not found: ['Reg. Number', 'Adviser', 'Option', 'Names']"
     ]
    }
   ],
   "source": [
    "get_as_dataframe(get_database('1EJQyD0NghC1lxalJCWINQYvqAZdnGDve', \"Group Score Sheet\", 'Sheet1'), usecols=['Names','Reg. Number','Adviser','Option'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84e9a84-bda7-402f-a830-c7546c47bf11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
